"""
Data Processor for Control Groups
ëŒ€ì¡°êµ° ëª¨ë¸ì„ ìœ„í•œ ë°ì´í„° ì²˜ë¦¬
"""

import os
import json
import torch
from torch.utils.data import Dataset, DataLoader, Subset
from transformers import AutoTokenizer, AutoProcessor
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from typing import Dict, List, Tuple, Optional, Union
import numpy as np
from PIL import Image
import librosa
import pandas as pd
from collections import defaultdict, Counter

from config import ControlGroupConfig
import sys
sys.path.append('../siglip')
from language_parsers import parse_all_languages
from models import AudioToMelSpectrogram

class ControlGroupDataset(Dataset):
    """ëŒ€ì¡°êµ° ëª¨ë¸ì„ ìœ„í•œ ë°ì´í„°ì…‹"""
    
    def __init__(self, 
                 data: List[Dict], 
                 config: ControlGroupConfig,
                 tokenizer: Optional[AutoTokenizer] = None,
                 processor: Optional[AutoProcessor] = None,
                 mode: str = "multimodal"):
        """
        Args:
            data: ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            config: ì„¤ì •
            tokenizer: í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì € (Text-only, Concatì—ì„œ ì‚¬ìš©)
            processor: ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ (Audio-only, Concatì—ì„œ ì‚¬ìš©)
            mode: "audio_only", "text_only", "multimodal"
        """
        self.data = data
        self.config = config
        self.tokenizer = tokenizer
        self.processor = processor
        self.mode = mode
        
        # siglip ë°©ì‹ ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        self.audio_processor = AudioToMelSpectrogram(
            sample_rate=16000,
            n_mels=128,
            n_fft=2048,
            hop_length=512,
            fmin=0.0,
            fmax=8000.0,
            image_size=224
        )
    
    def __len__(self) -> int:
        return len(self.data)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        item = self.data[idx]
        
        result = {
            'label': torch.tensor(item['label'], dtype=torch.long),
            'language': item['language'],
            'patient_id': item.get('patient_id', item['file_id']),
            'file_id': item['file_id']
        }
        
        # ì˜¤ë””ì˜¤ ì²˜ë¦¬ (Audio-only, Multimodal) - siglip ë°©ì‹ ì‚¬ìš©
        if self.mode in ["audio_only", "multimodal"] and self.processor is not None:
            try:
                audio_path = item.get('audio_path', item.get('spectrogram_path', ''))
                
                if audio_path and os.path.exists(audio_path):
                    # .npy íŒŒì¼ì¸ ê²½ìš° (ì „ì²˜ë¦¬ëœ ìŠ¤í™íŠ¸ë¡œê·¸ë¨)
                    if audio_path.endswith('.npy'):
                        try:
                            audio_spec = np.load(audio_path)
                            # ì´ë¯¸ ë©œìŠ¤í™í† ê·¸ë¨ í˜•íƒœë¼ë©´ ë°”ë¡œ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                            if len(audio_spec.shape) == 2:
                                image = self.audio_processor.melspectrogram_to_image(audio_spec)
                            else:
                                # 3ì°¨ì›ì¸ ê²½ìš° (3, H, W) -> (H, W) ë³€í™˜
                                if audio_spec.shape[0] == 3:
                                    # RGB ì±„ë„ í‰ê·  ë˜ëŠ” ì²« ë²ˆì§¸ ì±„ë„ ì‚¬ìš©
                                    audio_spec_2d = np.mean(audio_spec, axis=0)
                                else:
                                    audio_spec_2d = audio_spec[0] if len(audio_spec.shape) == 3 else audio_spec
                                image = self.audio_processor.melspectrogram_to_image(audio_spec_2d)
                        except Exception as e:
                            print(f"NPY íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {audio_path}: {e}")
                            # ë¹ˆ ë©œìŠ¤í™í† ê·¸ë¨ìœ¼ë¡œ ëŒ€ì²´
                            empty_spec = np.zeros((128, 100))
                            image = self.audio_processor.melspectrogram_to_image(empty_spec)
                    else:
                        # ì¼ë°˜ ì˜¤ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° siglip ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
                        image = self.audio_processor.process_audio_file(audio_path)
                    
                    # ì´ë¯¸ì§€ë¥¼ ViTìš© í…ì„œë¡œ ë³€í™˜
                    pixel_values = self.processor(images=image, return_tensors="pt")['pixel_values'][0]
                    result['pixel_values'] = pixel_values
                else:
                    # SigLIP ë°©ì‹: ì´ë¯¸ í•„í„°ë§ë˜ì–´ ì´ ê²½ìš°ëŠ” ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨
                    raise ValueError(f"ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ (í•„í„°ë§ ì˜¤ë¥˜): {audio_path}")
                    
            except Exception as e:
                # SigLIP ë°©ì‹: ì˜¤ë¥˜ ì‹œ ì˜ˆì™¸ ë°œìƒ (í•„í„°ë§ë˜ì–´ì•¼ í•  ìƒ˜í”Œ)
                raise ValueError(f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜ (í•„í„°ë§ ì˜¤ë¥˜): {e}")
        
        # í…ìŠ¤íŠ¸ ì²˜ë¦¬ (Text-only, Multimodal)
        if self.mode in ["text_only", "multimodal"] and self.tokenizer is not None:
            try:
                text = item['text']
                if text and text.strip():
                    # í† í°í™”
                    encoded = self.tokenizer(
                        text,
                        max_length=self.config.max_seq_length,
                        padding='max_length',
                        truncation=True,
                        return_tensors='pt'
                    )
                    result['input_ids'] = encoded['input_ids'][0]
                    result['attention_mask'] = encoded['attention_mask'][0]
                else:
                    # SigLIP ë°©ì‹: ì´ë¯¸ í•„í„°ë§ë˜ì–´ ì´ ê²½ìš°ëŠ” ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨
                    raise ValueError(f"í…ìŠ¤íŠ¸ ì—†ìŒ (í•„í„°ë§ ì˜¤ë¥˜): {item.get('file_id', 'unknown')}")
            except Exception as e:
                # SigLIP ë°©ì‹: ì˜¤ë¥˜ ì‹œ ì˜ˆì™¸ ë°œìƒ (í•„í„°ë§ë˜ì–´ì•¼ í•  ìƒ˜í”Œ)
                raise ValueError(f"í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜ (í•„í„°ë§ ì˜¤ë¥˜): {e}")
        
        return result

def load_multilingual_data(data_dir: str, languages: List[str]) -> List[Dict]:
    """ë©€í‹°ë§ê¶ ë°ì´í„° ë¡œë“œ"""
    
    print(f"ğŸ“‚ siglip íŒŒì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤êµ­ì–´ ë°ì´í„° ë¡œë“œ ì¤‘: {languages}")
    
    # siglip/language_parsers.pyì˜ parse_all_languages í•¨ìˆ˜ ì‚¬ìš©
    data = parse_all_languages(data_dir, languages)
    
    # ëŒ€ì¡°êµ° ëª¨ë¸ í˜¸í™˜ì„±ì„ ìœ„í•´ í•„ë“œ ì¶”ê°€
    for item in data:
        if 'audio_path' in item and 'spectrogram_path' not in item:
            item['spectrogram_path'] = item['audio_path']
        if 'spectrogram_path' in item and 'audio_available' not in item:
            item['audio_available'] = os.path.exists(item['spectrogram_path']) if item['spectrogram_path'] else False
        
        # patient_idê°€ ì—†ëŠ” ê²½ìš° file_idì—ì„œ ì¶”ì¶œ
        if 'patient_id' not in item or not item['patient_id']:
            file_id = item.get('file_id', 'unknown')
            # íŒŒì¼ëª…ì—ì„œ í™˜ì ID ì¶”ì¶œ (ê¸°ë³¸ ë¡œì§)
            patient_id = file_id.split('_')[0] if '_' in file_id else file_id
            item['patient_id'] = patient_id
    
    print(f"ğŸ“Š ì „ì²´ ë¡œë“œëœ ë°ì´í„°: {len(data)}ê°œ ìƒ˜í”Œ")
    
    # SigLIPê³¼ ë™ì¼í•œ ë°©ì‹: ëˆ„ë½ ë°ì´í„°ê°€ ìˆëŠ” ìƒ˜í”Œ í•„í„°ë§
    filtered_data = []
    excluded_count = 0
    
    for item in data:
        # ì˜¤ë””ì˜¤ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        audio_available = False
        audio_path = item.get('audio_path') or item.get('spectrogram_path', '')
        if audio_path and os.path.exists(audio_path):
            audio_available = True
        
        # í…ìŠ¤íŠ¸ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        text_available = False
        text = item.get('text', '')
        if text and text.strip():
            text_available = True
        
        # ì™„ì „í•œ ìƒ˜í”Œë§Œ í¬í•¨ (SigLIP ë°©ì‹)
        # ë©€í‹°ëª¨ë‹¬ ì‹¤í—˜ì„ ìœ„í•´ ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ ëª¨ë‘ í•„ìš”
        if audio_available and text_available:
            filtered_data.append(item)
        else:
            excluded_count += 1
            missing_parts = []
            if not audio_available:
                missing_parts.append("ì˜¤ë””ì˜¤")
            if not text_available:
                missing_parts.append("í…ìŠ¤íŠ¸")
            print(f"âš ï¸ ëˆ„ë½ ë°ì´í„°ë¡œ ì¸í•œ ìƒ˜í”Œ ì œì™¸: {item.get('file_id', 'unknown')} ({', '.join(missing_parts)} ëˆ„ë½)")
    
    print(f"ğŸ” ë°ì´í„° í•„í„°ë§ ê²°ê³¼:")
    print(f"  âœ… ì™„ì „í•œ ìƒ˜í”Œ: {len(filtered_data)}ê°œ")
    print(f"  âŒ ì œì™¸ëœ ìƒ˜í”Œ: {excluded_count}ê°œ")
    print(f"  ğŸ“Š ì‚¬ìš©ë¥ : {len(filtered_data)/(len(filtered_data)+excluded_count)*100:.1f}%")
    
    # í•„í„°ë§ëœ ë°ì´í„° ì‚¬ìš©
    data = filtered_data
    
    # ì–¸ì–´ë³„ ë¶„í¬ (í•„í„°ë§ í›„)
    lang_counts = Counter([item['language'] for item in data])
    print("ğŸ“ˆ ì–¸ì–´ë³„ ë¶„í¬ (í•„í„°ë§ í›„):")
    for lang, count in lang_counts.items():
        print(f"  {lang}: {count}ê°œ")
    
    # ë¼ë²¨ë³„ ë¶„í¬
    label_counts = Counter([item['label'] for item in data])
    print("ğŸ“ˆ ë¼ë²¨ë³„ ë¶„í¬:")
    for label, count in label_counts.items():
        label_name = "ì •ìƒ" if label == 0 else "ì¹˜ë§¤"
        print(f"  {label_name}: {count}ê°œ")
    
    return data

def load_language_data(lang_dir: str, language: str) -> List[Dict]:
    """íŠ¹ì • ì–¸ì–´ ë°ì´í„° ë¡œë“œ"""
    
    data = []
    
    # ì˜ì–´ëŠ” íŠ¹ë³„í•œ êµ¬ì¡°ë¥¼ ê°€ì§
    if language == "English":
        return load_english_data(lang_dir, language)
    
    # í…ìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ
    text_dir = os.path.join(lang_dir, 'textdata')
    voice_dir = os.path.join(lang_dir, 'voicedata')
    
    if not os.path.exists(text_dir):
        print(f"    âš ï¸ í…ìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ì—†ìŒ: {text_dir}")
        return data
    
    # HC (ì •ìƒ) ë° AD (ì¹˜ë§¤) ë°ì´í„° ë¡œë“œ
    for label, label_name in [(0, 'HC'), (1, 'AD')]:
        text_label_dir = os.path.join(text_dir, label_name)
        voice_label_dir = os.path.join(voice_dir, label_name) if os.path.exists(voice_dir) else None
        
        if not os.path.exists(text_label_dir):
            continue
        
        # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
        for filename in os.listdir(text_label_dir):
            if not filename.endswith('.txt'):
                continue
            
            file_id = filename.replace('.txt', '')
            text_path = os.path.join(text_label_dir, filename)
            
            # í…ìŠ¤íŠ¸ ì½ê¸°
            try:
                with open(text_path, 'r', encoding='utf-8') as f:
                    text = f.read().strip()
            except:
                continue
            
            if not text:
                continue
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
            spectrogram_path = None
            if voice_label_dir and os.path.exists(voice_label_dir):
                # ì—¬ëŸ¬ í™•ì¥ì ì‹œë„
                for ext in ['.wav', '.mp3', '.mp4', '.png', '.jpg']:
                    audio_file = os.path.join(voice_label_dir, f"{file_id}{ext}")
                    if os.path.exists(audio_file):
                        # ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì €ì¥
                        if ext in ['.png', '.jpg']:
                            spectrogram_path = audio_file
                        else:
                            # ì˜¤ë””ì˜¤ íŒŒì¼ì„ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ìœ¼ë¡œ ë³€í™˜í•œ ê²½ë¡œ (ê°€ì •)
                            spectrogram_path = audio_file.replace(ext, '_spectrogram.png')
                        break
            
            # í™˜ì ID ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
            patient_id = file_id.split('_')[0] if '_' in file_id else file_id
            
            data.append({
                'file_id': file_id,
                'patient_id': patient_id,
                'language': language,
                'label': label,
                'text': text,
                'text_path': text_path,
                'spectrogram_path': spectrogram_path or "",
                'audio_available': spectrogram_path is not None and os.path.exists(spectrogram_path)
            })
    
    return data

def create_stratified_split(
    dataset: List[Dict], 
    train_split: float = 0.7, 
    val_split: float = 0.1, 
    test_split: float = 0.2,
    random_seed: int = 42,
    split_by_patient: bool = True
) -> Tuple[List[int], List[int], List[int]]:
    """ê³„ì¸µí™”ëœ ë°ì´í„° ë¶„í• """
    
    if split_by_patient:
        print("ğŸ‘¥ í™˜ì ë‹¨ìœ„ Stratified Split ìˆ˜í–‰ ì¤‘...")
        return create_patient_based_split(dataset, train_split, val_split, test_split, random_seed)
    else:
        print("ğŸ“„ ìƒ˜í”Œ ë‹¨ìœ„ Stratified Split ìˆ˜í–‰ ì¤‘...")
        return create_sample_based_split(dataset, train_split, val_split, test_split, random_seed)

def create_patient_based_split(
    dataset: List[Dict], 
    train_split: float = 0.7, 
    val_split: float = 0.1, 
    test_split: float = 0.2,
    random_seed: int = 42
) -> Tuple[List[int], List[int], List[int]]:
    """í™˜ì ë‹¨ìœ„ ê³„ì¸µí™” ë¶„í• """
    
    # í™˜ìë³„ ë°ì´í„° ê·¸ë£¹í•‘
    patient_groups = defaultdict(list)
    for idx, item in enumerate(dataset):
        patient_id = item.get('patient_id', item.get('file_id', f'patient_{idx}'))
        key = f"{patient_id}_{item['language']}_{item['label']}"
        patient_groups[key].append(idx)
    
    # ê³„ì¸µí™” í‚¤ ìƒì„±
    stratify_keys = []
    patient_indices = []
    
    for key, indices in patient_groups.items():
        _, language, label = key.rsplit('_', 2)
        stratify_key = f"{language}_{label}"
        stratify_keys.append(stratify_key)
        patient_indices.append(indices)
    
    print(f"  ì „ì²´ í™˜ì ê·¸ë£¹: {len(patient_indices)}ê°œ")
    print(f"  Stratify í‚¤ ë¶„í¬: {Counter(stratify_keys)}")
    
    # í™˜ì ê·¸ë£¹ ë¶„í• 
    if test_split > 0:
        # 3-way split
        train_patient_idx, temp_patient_idx = train_test_split(
            range(len(patient_indices)),
            test_size=(val_split + test_split),
            stratify=stratify_keys,
            random_state=random_seed
        )
        
        # val/test ë¶„í• ì„ ìœ„í•œ ìƒˆë¡œìš´ stratify í‚¤
        temp_stratify_keys = [stratify_keys[i] for i in temp_patient_idx]
        val_ratio = val_split / (val_split + test_split)
        
        val_patient_idx, test_patient_idx = train_test_split(
            temp_patient_idx,
            test_size=(1 - val_ratio),
            stratify=temp_stratify_keys,
            random_state=random_seed
        )
    else:
        # 2-way split (cross-lingual ëª¨ë“œ)
        train_patient_idx, val_patient_idx = train_test_split(
            range(len(patient_indices)),
            test_size=val_split,
            stratify=stratify_keys,
            random_state=random_seed
        )
        test_patient_idx = []
    
    # ìƒ˜í”Œ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
    train_indices = []
    for i in train_patient_idx:
        train_indices.extend(patient_indices[i])
    
    val_indices = []
    for i in val_patient_idx:
        val_indices.extend(patient_indices[i])
    
    test_indices = []
    for i in test_patient_idx:
        test_indices.extend(patient_indices[i])
    
    print(f"ğŸ“ˆ ë¶„í•  ê²°ê³¼:")
    print(f"  í›ˆë ¨: {len(train_indices)}ê°œ ìƒ˜í”Œ")
    print(f"  ê²€ì¦: {len(val_indices)}ê°œ ìƒ˜í”Œ")
    print(f"  í…ŒìŠ¤íŠ¸: {len(test_indices)}ê°œ ìƒ˜í”Œ")
    
    return train_indices, val_indices, test_indices

def create_sample_based_split(
    dataset: List[Dict], 
    train_split: float = 0.7, 
    val_split: float = 0.1, 
    test_split: float = 0.2,
    random_seed: int = 42
) -> Tuple[List[int], List[int], List[int]]:
    """ìƒ˜í”Œ ë‹¨ìœ„ ê³„ì¸µí™” ë¶„í• """
    
    # ê³„ì¸µí™” í‚¤ ìƒì„±
    stratify_keys = []
    for item in dataset:
        stratify_key = f"{item['language']}_{item['label']}"
        stratify_keys.append(stratify_key)
    
    print(f"  ì „ì²´ ìƒ˜í”Œ: {len(dataset)}ê°œ")
    print(f"  Stratify í‚¤ ë¶„í¬: {Counter(stratify_keys)}")
    
    indices = list(range(len(dataset)))
    
    if test_split > 0:
        # 3-way split
        train_indices, temp_indices = train_test_split(
            indices,
            test_size=(val_split + test_split),
            stratify=stratify_keys,
            random_state=random_seed
        )
        
        temp_stratify_keys = [stratify_keys[i] for i in temp_indices]
        val_ratio = val_split / (val_split + test_split)
        
        val_indices, test_indices = train_test_split(
            temp_indices,
            test_size=(1 - val_ratio),
            stratify=temp_stratify_keys,
            random_state=random_seed
        )
    else:
        # 2-way split
        train_indices, val_indices = train_test_split(
            indices,
            test_size=val_split,
            stratify=stratify_keys,
            random_state=random_seed
        )
        test_indices = []
    
    print(f"ğŸ“ˆ ë¶„í•  ê²°ê³¼:")
    print(f"  í›ˆë ¨: {len(train_indices)}ê°œ ìƒ˜í”Œ")
    print(f"  ê²€ì¦: {len(val_indices)}ê°œ ìƒ˜í”Œ")
    print(f"  í…ŒìŠ¤íŠ¸: {len(test_indices)}ê°œ ìƒ˜í”Œ")
    
    return train_indices, val_indices, test_indices

# ë” ì´ìƒ í•„ìš” ì—†ìŒ - siglipì˜ language_parsers.py ì‚¬ìš©

def compute_class_weights(dataset: Union[List[Dict], Subset], config: ControlGroupConfig) -> np.ndarray:
    """í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    
    if isinstance(dataset, Subset):
        labels = [dataset.dataset.data[i]['label'] for i in dataset.indices]
    else:
        labels = [item['label'] for item in dataset]
    
    unique_labels = np.unique(labels)
    class_weights = compute_class_weight(
        class_weight='balanced',
        classes=unique_labels,
        y=labels
    )
    
    print(f"ğŸ“Š í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°:")
    for label, weight in zip(unique_labels, class_weights):
        label_name = "ì •ìƒ(HC)" if label == 0 else "ì¹˜ë§¤(AD)"
        print(f"  {label_name}: {weight:.4f}")
    
    return class_weights

def create_dataloaders(
    config: ControlGroupConfig,
    mode: str = "multimodal",
    tokenizer: Optional[AutoTokenizer] = None,
    processor: Optional[AutoProcessor] = None
) -> Tuple[DataLoader, DataLoader, Optional[DataLoader]]:
    """ë°ì´í„°ë¡œë” ìƒì„±"""
    
    # ë°ì´í„° ë¡œë“œ
    all_data = load_multilingual_data(config.data_dir, config.languages)
    
    if len(all_data) == 0:
        raise ValueError("ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
    
    # ë°ì´í„° ë¶„í• 
    train_indices, val_indices, test_indices = create_stratified_split(
        all_data,
        split_by_patient=config.split_by_patient,
        random_seed=config.random_seed
    )
    
    # ë°ì´í„°ì…‹ ìƒì„±
    full_dataset = ControlGroupDataset(all_data, config, tokenizer, processor, mode)
    
    train_dataset = Subset(full_dataset, train_indices)
    val_dataset = Subset(full_dataset, val_indices)
    test_dataset = Subset(full_dataset, test_indices) if test_indices else None
    
    # ë°ì´í„°ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=config.batch_size,
        shuffle=True,
        num_workers=4,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    test_loader = None
    if test_dataset:
        test_loader = DataLoader(
            test_dataset,
            batch_size=config.batch_size,
            shuffle=False,
            num_workers=4,
            pin_memory=True
        )
    
    return train_loader, val_loader, test_loader
