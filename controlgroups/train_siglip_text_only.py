#!/usr/bin/env python3
"""
SigLIP-Text-Only ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
SigLIPì˜ í…ìŠ¤íŠ¸ ì¸ì½”ë” + Gemma í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ëŠ” í…ìŠ¤íŠ¸ ì „ìš© ëŒ€ì¡°êµ°
"""

import os
import sys
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import wandb
from torch.utils.data import DataLoader
from typing import Dict, List, Tuple
from sklearn.utils.class_weight import compute_class_weight
from tqdm import tqdm

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import TextOnlyConfig
from siglip_control_models import SigLIPTextOnlyModel, compute_metrics, compute_language_specific_metrics
from data_processor import create_dataloaders
from transformers import AutoTokenizer

def compute_class_weights(train_labels: List[int]) -> np.ndarray:
    """í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    unique_labels = np.unique(train_labels)
    class_weights = compute_class_weight('balanced', classes=unique_labels, y=train_labels)
    return class_weights

def compute_target_languages_avg_macro_f1(language_metrics: Dict[str, Dict[str, float]], 
                                        target_languages: List[str]) -> float:
    """íƒ€ê²Ÿ ì–¸ì–´ë“¤ì˜ í‰ê·  Macro F1 ê³„ì‚°"""
    
    valid_macro_f1s = []
    for lang in target_languages:
        if lang in language_metrics and 'macro_f1' in language_metrics[lang]:
            if language_metrics[lang]['macro_f1'] > 0:
                valid_macro_f1s.append(language_metrics[lang]['macro_f1'])
                print(f"  {lang} Macro F1: {language_metrics[lang]['macro_f1']:.4f}")
    
    if valid_macro_f1s:
        avg_macro_f1 = np.mean(valid_macro_f1s)
        print(f"  í‰ê·  Macro F1 ({len(valid_macro_f1s)}ê°œ ì–¸ì–´): {avg_macro_f1:.4f}")
        return avg_macro_f1
    else:
        print("  âš ï¸ ìœ íš¨í•œ ì–¸ì–´ë³„ Macro F1ê°€ ì—†ì–´ ì „ì²´ Macro F1 ì‚¬ìš©")
        return 0.0

def train_epoch(model: nn.Module, train_loader: DataLoader, optimizer: optim.Optimizer, 
                config: TextOnlyConfig, scheduler=None) -> Tuple[float, Dict[str, float]]:
    """í•œ ì—í¬í¬ í›ˆë ¨"""
    
    model.train()
    total_loss = 0.0
    all_preds = []
    all_labels = []
    all_probs = []
    all_languages = []
    
    for batch in tqdm(train_loader, desc="í›ˆë ¨"):
        optimizer.zero_grad()
        
        # ì…ë ¥ ì¤€ë¹„
        input_ids = batch['input_ids'].to(config.device)
        attention_mask = batch['attention_mask'].to(config.device)
        labels = batch['label'].to(config.device)
        languages = batch['language']
        
        # ìˆœì „íŒŒ
        logits = model(input_ids, attention_mask)
        loss = model.compute_loss(logits, labels)
        
        # ì—­ì „íŒŒ
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        
        # ì˜ˆì¸¡ ë° í™•ë¥  ê³„ì‚°
        if config.num_classes == 2:
            probs = torch.sigmoid(logits[:, 1] - logits[:, 0])
            preds = (probs > 0.5).long()
        else:
            probs = torch.softmax(logits, dim=-1)
            preds = torch.argmax(logits, dim=-1)
        
        # gradient ë¶„ë¦¬í•˜ì—¬ numpy ë³€í™˜
        all_preds.extend(preds.detach().cpu().numpy())
        all_labels.extend(labels.detach().cpu().numpy())
        all_languages.extend(languages)
        
        # í™•ë¥  ì²˜ë¦¬ - gradient ë¶„ë¦¬ ë° ì˜ˆì™¸ ì²˜ë¦¬
        try:
            if config.num_classes == 2:
                all_probs.extend(probs.detach().cpu().numpy())
            else:
                all_probs.extend(probs[:, 1].detach().cpu().numpy())
        except Exception as e:
            print(f"âš ï¸ í™•ë¥  ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            # í´ë°±: sigmoid í™•ë¥  ì‚¬ìš©
            prob_values = torch.sigmoid(logits).detach().cpu().numpy()
            if len(prob_values.shape) > 1 and prob_values.shape[1] > 1:
                all_probs.extend(prob_values[:, 1])
            else:
                all_probs.extend(prob_values.flatten())
    
    if scheduler:
        scheduler.step()
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    avg_loss = total_loss / len(train_loader)
    metrics = compute_metrics(np.array(all_preds), np.array(all_labels), np.array(all_probs))
    
    return avg_loss, metrics

def validate_epoch(model: nn.Module, val_loader: DataLoader, config: TextOnlyConfig) -> Tuple[float, Dict[str, float], Dict[str, Dict[str, float]]]:
    """í•œ ì—í¬í¬ ê²€ì¦"""
    
    model.eval()
    total_loss = 0.0
    all_preds = []
    all_labels = []
    all_probs = []
    all_languages = []
    
    with torch.no_grad():
        for batch in tqdm(val_loader, desc="ê²€ì¦"):
            # ì…ë ¥ ì¤€ë¹„
            input_ids = batch['input_ids'].to(config.device)
            attention_mask = batch['attention_mask'].to(config.device)
            labels = batch['label'].to(config.device)
            languages = batch['language']
            
            # ìˆœì „íŒŒ
            logits = model(input_ids, attention_mask)
            loss = model.compute_loss(logits, labels)
            
            total_loss += loss.item()
            
            # ì˜ˆì¸¡ ë° í™•ë¥  ê³„ì‚°
            if config.num_classes == 2:
                probs = torch.sigmoid(logits[:, 1] - logits[:, 0])
                preds = (probs > 0.5).long()
            else:
                probs = torch.softmax(logits, dim=-1)
                preds = torch.argmax(logits, dim=-1)
            
            # numpy ë³€í™˜
            all_preds.extend(preds.detach().cpu().numpy())
            all_labels.extend(labels.detach().cpu().numpy())
            all_languages.extend(languages)
            
            # í™•ë¥  ì²˜ë¦¬ - ì˜ˆì™¸ ì²˜ë¦¬
            try:
                if config.num_classes == 2:
                    all_probs.extend(probs.detach().cpu().numpy())
                else:
                    all_probs.extend(probs[:, 1].detach().cpu().numpy())
            except Exception as e:
                print(f"âš ï¸ í™•ë¥  ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
                # í´ë°±: sigmoid í™•ë¥  ì‚¬ìš©
                prob_values = torch.sigmoid(logits).detach().cpu().numpy()
                if len(prob_values.shape) > 1 and prob_values.shape[1] > 1:
                    all_probs.extend(prob_values[:, 1])
                else:
                    all_probs.extend(prob_values.flatten())
    
    # ë©”íŠ¸ë¦­ ê³„ì‚°
    avg_loss = total_loss / len(val_loader)
    metrics = compute_metrics(np.array(all_preds), np.array(all_labels), np.array(all_probs))
    language_metrics = compute_language_specific_metrics(
        np.array(all_preds), np.array(all_labels), np.array(all_probs), 
        all_languages, metrics['optimal_threshold']
    )
    
    return avg_loss, metrics, language_metrics

def train_model(config: TextOnlyConfig) -> Tuple[nn.Module, str]:
    """ëª¨ë¸ í›ˆë ¨"""
    
    print("ğŸ”¥ SigLIP-Text-Only ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    print(f"  ì–¸ì–´: {config.languages}")
    print(f"  SigLIP ëª¨ë¸: {config.siglip_model}")
    print(f"  í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì €: {config.text_tokenizer}")
    print(f"  ë°°ì¹˜ í¬ê¸°: {config.batch_size}")
    print(f"  í•™ìŠµë¥ : {config.learning_rate}")
    print(f"  ì—í¬í¬: {config.num_epochs}")
    print(f"  Early Stopping: {config.early_stopping_patience} epochs")
    
    # ë©€í‹° GPU ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = config.device
    if torch.cuda.is_available():
        device_count = torch.cuda.device_count()
        print(f"  ì‚¬ìš© ê°€ëŠ¥í•œ GPU: {device_count}ê°œ")
        print(f"  ì£¼ ë””ë°”ì´ìŠ¤: {device}")
        if device_count > 1:
            print(f"  ë©€í‹° GPU ëª¨ë“œ: GPU 0-{device_count-1} ì‚¬ìš©")
    else:
        print(f"  ë””ë°”ì´ìŠ¤: {device}")
    
    # Gemma í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(config.text_tokenizer)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    # ë°ì´í„°ë¡œë” ìƒì„±
    train_loader, val_loader, test_loader = create_dataloaders(
        config, mode="text_only", tokenizer=tokenizer
    )
    
    # ëª¨ë¸ ìƒì„± ë° ë©€í‹° GPU ì„¤ì •
    model = SigLIPTextOnlyModel(config).to(device)
    
    # ë©€í‹° GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ DataParallel ì ìš©
    if torch.cuda.is_available() and torch.cuda.device_count() > 1:
        print(f"  ğŸ”¥ ë©€í‹° GPU í›ˆë ¨ í™œì„±í™”: {torch.cuda.device_count()}ê°œ GPU ì‚¬ìš©")
        model = nn.DataParallel(model)
        use_dataparallel = True
    else:
        use_dataparallel = False
    
    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ë° ì ìš©
    if config.auto_class_weights:
        # DataParallel ì‚¬ìš© ì‹œ train_loader.dataset.data ì ‘ê·¼ ë°©ì‹ ìˆ˜ì •
        if hasattr(train_loader.dataset, 'data'):
            train_labels = [item['label'] for item in train_loader.dataset.data]
        else:
            # Subsetì¸ ê²½ìš°
            train_labels = [train_loader.dataset.dataset.data[i]['label'] for i in train_loader.dataset.indices]
        
        class_weights = compute_class_weights(train_labels)
        print(f"ğŸ“Š ìë™ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weights}")
        
        # ëª¨ë¸ì— í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©
        if use_dataparallel:
            model.module.setup_loss_function(class_weights)
        else:
            model.setup_loss_function(class_weights)
    
    # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬
    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=0.01)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.num_epochs)
    
    # Wandb ì´ˆê¸°í™”
    if config.log_wandb:
        wandb.init(
            project="dementia-controlgroups",
            name=f"siglip-text-only-{'_'.join(config.languages)}",
            config={
                "model_type": "siglip_text_only",
                "siglip_model": config.siglip_model,
                "text_tokenizer": config.text_tokenizer,
                "languages": config.languages,
                "batch_size": config.batch_size,
                "learning_rate": config.learning_rate,
                "num_epochs": config.num_epochs,
                "early_stopping_patience": config.early_stopping_patience,
                "loss_type": config.loss_type,
                "auto_class_weights": config.auto_class_weights,
                "best_model_metric": config.best_model_metric,
                "target_languages": config.target_languages,
                "split_by_patient": config.split_by_patient
            }
        )
    
    # í›ˆë ¨ ë£¨í”„
    best_metric = 0.0
    patience_counter = 0
    best_model_path = None
    
    for epoch in range(config.num_epochs):
        print(f"\nğŸ”„ Epoch {epoch+1}/{config.num_epochs}")
        
        # í›ˆë ¨
        train_loss, train_metrics = train_epoch(model, train_loader, optimizer, config, scheduler)
        
        # ê²€ì¦
        val_loss, val_metrics, val_lang_metrics = validate_epoch(model, val_loader, config)
        
        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ ê¸°ì¤€ì— ë”°ë¥¸ í˜„ì¬ ë©”íŠ¸ë¦­ ê³„ì‚°
        if config.best_model_metric == "val_macro_f1":
            current_metric = val_metrics['macro_f1']
        elif config.best_model_metric == "avg_lang_macro_f1":
            current_metric = compute_target_languages_avg_macro_f1(val_lang_metrics, config.target_languages)
        else:  # val_auc (ê¸°ë³¸ê°’)
            current_metric = val_metrics['auc']
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"  í›ˆë ¨ ì†ì‹¤: {train_loss:.4f}")
        print(f"  ê²€ì¦ ì†ì‹¤: {val_loss:.4f}")
        print(f"  í›ˆë ¨ Acc: {train_metrics['accuracy']:.4f}, Macro F1: {train_metrics['macro_f1']:.4f}, AUC: {train_metrics['auc']:.4f}")
        print(f"  ê²€ì¦ Acc: {val_metrics['accuracy']:.4f}, Macro F1: {val_metrics['macro_f1']:.4f}, AUC: {val_metrics['auc']:.4f}")
        print(f"  í˜„ì¬ {config.best_model_metric}: {current_metric:.4f}")
        
        # ì–¸ì–´ë³„ ê²°ê³¼ ì¶œë ¥
        print("  ğŸ“Š ì–¸ì–´ë³„ ê²€ì¦ ì„±ëŠ¥:")
        for lang, metrics in val_lang_metrics.items():
            print(f"    {lang} - Acc: {metrics['accuracy']:.4f}, Macro F1: {metrics['macro_f1']:.4f}, AUC: {metrics['auc']:.4f}")
        
        # Wandb ë¡œê¹…
        if config.log_wandb:
            log_dict = {
                'epoch': epoch + 1,
                'train_loss': train_loss,
                'val_loss': val_loss,
                'train_accuracy': train_metrics['accuracy'],
                'train_macro_f1': train_metrics['macro_f1'],
                'train_auc': train_metrics['auc'],
                'val_accuracy': val_metrics['accuracy'],
                'val_macro_f1': val_metrics['macro_f1'],
                'val_auc': val_metrics['auc'],
                'current_metric': current_metric,
                'learning_rate': scheduler.get_last_lr()[0]
            }
            
            # ì–¸ì–´ë³„ ë©”íŠ¸ë¦­ ì¶”ê°€
            for lang, metrics in val_lang_metrics.items():
                for metric_name, value in metrics.items():
                    log_dict[f'val_{lang}_{metric_name}'] = value
            
            wandb.log(log_dict)
        
        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥
        if current_metric > best_metric:
            best_metric = current_metric
            patience_counter = 0
            
            # ëª¨ë¸ ì €ì¥
            os.makedirs(config.output_dir, exist_ok=True)
            best_model_path = os.path.join(config.output_dir, f"best_siglip_text_only_{'_'.join(config.languages)}.pt")
            
            model_to_save = model.module if use_dataparallel else model
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model_to_save.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_metric': best_metric,
                'config': config
            }, best_model_path)
            
            print(f"  âœ… ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥: {config.best_model_metric} = {best_metric:.4f}")
        else:
            patience_counter += 1
            print(f"  â³ Early Stopping: {patience_counter}/{config.early_stopping_patience}")
        
        # Early Stopping
        if patience_counter >= config.early_stopping_patience:
            print(f"  ğŸ›‘ Early Stopping ë°œë™! ë² ìŠ¤íŠ¸ {config.best_model_metric}: {best_metric:.4f}")
            break
    
    # ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ
    if best_model_path and os.path.exists(best_model_path):
        print(f"\nğŸ“¥ ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ: {best_model_path}")
        checkpoint = torch.load(best_model_path, map_location=device)
        model_to_load = model.module if use_dataparallel else model
        model_to_load.load_state_dict(checkpoint['model_state_dict'])
    
    # ìµœì¢… í…ŒìŠ¤íŠ¸
    if test_loader is not None:
        print(f"\nğŸ§ª ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€")
        test_loss, test_metrics, test_lang_metrics = validate_epoch(model, test_loader, config)
        
        print(f"ğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
        print(f"  ì „ì²´ - Acc: {test_metrics['accuracy']:.4f}, Macro F1: {test_metrics['macro_f1']:.4f}, "
              f"AUC: {test_metrics['auc']:.4f}")
        
        print(f"ğŸ“Š ì–¸ì–´ë³„ í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
        for lang, metrics in test_lang_metrics.items():
            print(f"  {lang} - Acc: {metrics['accuracy']:.4f}, Macro F1: {metrics['macro_f1']:.4f}, "
                  f"AUC: {metrics['auc']:.4f}")
        
        if config.log_wandb:
            test_log_dict = {'test_accuracy': test_metrics['accuracy'],
                           'test_macro_f1': test_metrics['macro_f1'],
                           'test_auc': test_metrics['auc']}
            
            for lang, metrics in test_lang_metrics.items():
                for metric_name, value in metrics.items():
                    test_log_dict[f'test_{lang}_{metric_name}'] = value
            
            wandb.log(test_log_dict)
    
    if config.log_wandb:
        wandb.finish()
    
    print(f"\nâœ… SigLIP-Text-Only ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ! ë² ìŠ¤íŠ¸ {config.best_model_metric}: {best_metric:.4f}")
    return model, best_model_path

def main():
    parser = argparse.ArgumentParser(description="SigLIP-Text-Only ëª¨ë¸ í›ˆë ¨")
    
    # ë°ì´í„° ê´€ë ¨
    parser.add_argument('--data_dir', type=str, default='../../training_dset', help='ë°ì´í„° ë””ë ‰í† ë¦¬')
    parser.add_argument('--languages', nargs='+', default=['English', 'Mandarin'], help='ì‚¬ìš©í•  ì–¸ì–´ë“¤')
    
    # í›ˆë ¨ ê´€ë ¨
    parser.add_argument('--batch_size', type=int, default=10, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--learning_rate', type=float, default=2e-5, help='í•™ìŠµë¥ ')
    parser.add_argument('--num_epochs', type=int, default=100, help='ì—í¬í¬ ìˆ˜')
    parser.add_argument('--early_stopping_patience', type=int, default=15, help='Early stopping patience')
    
    # ëª¨ë¸ ê´€ë ¨
    parser.add_argument('--siglip_model', type=str, default='google/siglip-base-patch16-224', help='SigLIP ëª¨ë¸')
    parser.add_argument('--text_tokenizer', type=str, default='google/gemma-2b', help='í…ìŠ¤íŠ¸ í† í¬ë‚˜ì´ì €')
    parser.add_argument('--loss_type', type=str, default='focal', choices=['focal', 'bce'], help='ì†ì‹¤ í•¨ìˆ˜')
    parser.add_argument('--focal_alpha', type=float, default=1.0, help='Focal loss alpha')
    parser.add_argument('--focal_gamma', type=float, default=2.0, help='Focal loss gamma')
    parser.add_argument('--auto_class_weights', type=str, default='true', choices=['true', 'false'], help='ìë™ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜')
    parser.add_argument('--best_model_metric', type=str, default='avg_lang_macro_f1', 
                        choices=['val_macro_f1', 'avg_lang_macro_f1', 'val_auc'], help='ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ ê¸°ì¤€')
    parser.add_argument('--target_languages', nargs='*', help='íƒ€ê²Ÿ ì–¸ì–´ë“¤ (ê¸°ë³¸ê°’: languagesì™€ ë™ì¼)')
    parser.add_argument('--split_by_patient', type=str, default='true', choices=['true', 'false'], help='í™˜ì ë‹¨ìœ„ ë¶„í• ')
    
    # ì¶œë ¥ ê´€ë ¨
    parser.add_argument('--output_dir', type=str, default='../modules/outputs/controlgroups', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--no_wandb', action='store_true', help='Wandb ë¹„í™œì„±í™”')
    
    args = parser.parse_args()
    
    # ì„¤ì • ìƒì„±
    config = TextOnlyConfig(
        data_dir=args.data_dir,
        languages=args.languages,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        num_epochs=args.num_epochs,
        early_stopping_patience=args.early_stopping_patience,
        siglip_model=args.siglip_model,
        text_tokenizer=args.text_tokenizer,
        loss_type=args.loss_type,
        focal_alpha=args.focal_alpha,
        focal_gamma=args.focal_gamma,
        auto_class_weights=(args.auto_class_weights.lower() == 'true'),
        best_model_metric=args.best_model_metric,
        target_languages=args.target_languages or args.languages,
        split_by_patient=(args.split_by_patient.lower() == 'true'),
        output_dir=args.output_dir,
        log_wandb=(not args.no_wandb)
    )
    
    # í›ˆë ¨ ì‹¤í–‰
    train_model(config)

if __name__ == "__main__":
    main()
