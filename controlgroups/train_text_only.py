"""
Text-only Model Training Script
Text-only (Gemma Encoder, multilingual joint) í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import argparse
import torch
import torch.nn as nn
import numpy as np
import wandb
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR
from transformers import AutoTokenizer
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
from typing import Dict, List, Tuple
import json
from datetime import datetime

from config import TextOnlyConfig
from models import TextOnlyModel, compute_metrics, compute_language_specific_metrics
from data_processor import create_dataloaders, compute_class_weights

def train_epoch(model: nn.Module, 
                train_loader, 
                optimizer, 
                scheduler,
                device: str,
                config: TextOnlyConfig) -> Dict[str, float]:
    """í•œ ì—í¬í¬ í›ˆë ¨"""
    
    model.train()
    total_loss = 0.0
    all_preds = []
    all_labels = []
    all_probs = []
    
    for batch_idx, batch in enumerate(train_loader):
        # ë°ì´í„° ì´ë™
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['label'].to(device)
        
        # Forward pass
        optimizer.zero_grad()
        logits = model(input_ids, attention_mask)
        loss = model.compute_loss(logits, labels)
        
        # Backward pass
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        
        # ì˜ˆì¸¡ ë° í™•ë¥  ê³„ì‚°
        if config.num_classes == 2:
            probs = torch.sigmoid(logits[:, 1] - logits[:, 0])
            preds = (probs > 0.5).long()
        else:
            probs = torch.softmax(logits, dim=-1)
            preds = torch.argmax(logits, dim=-1)
        
        # gradient ë¶„ë¦¬í•˜ì—¬ numpy ë³€í™˜
        all_preds.extend(preds.detach().cpu().numpy())
        all_labels.extend(labels.detach().cpu().numpy())
        
        # í™•ë¥  ì²˜ë¦¬ - gradient ë¶„ë¦¬ ë° ì˜ˆì™¸ ì²˜ë¦¬
        try:
            if config.num_classes == 2:
                all_probs.extend(probs.detach().cpu().numpy())
            else:
                all_probs.extend(probs[:, 1].detach().cpu().numpy())
        except Exception as e:
            print(f"âš ï¸ í™•ë¥  ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            # í´ë°±: sigmoid í™•ë¥  ì‚¬ìš©
            prob_values = torch.sigmoid(logits).detach().cpu().numpy()
            if len(prob_values.shape) > 1 and prob_values.shape[1] > 1:
                all_probs.extend(prob_values[:, 1])
            else:
                all_probs.extend(prob_values.flatten())
    
    if scheduler:
        scheduler.step()
    
    # ì§€í‘œ ê³„ì‚°
    metrics = compute_metrics(
        np.array(all_labels),
        np.array(all_preds),
        np.array(all_probs)
    )
    
    metrics['loss'] = total_loss / len(train_loader)
    return metrics

def validate_epoch(model: nn.Module,
                   val_loader,
                   device: str,
                   config: TextOnlyConfig) -> Tuple[Dict[str, float], Dict[str, Dict[str, float]]]:
    """ê²€ì¦"""
    
    model.eval()
    total_loss = 0.0
    all_preds = []
    all_labels = []
    all_probs = []
    all_languages = []
    
    with torch.no_grad():
        for batch in val_loader:
            # ë°ì´í„° ì´ë™
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['label'].to(device)
            languages = batch['language']
            
            # Forward pass
            logits = model(input_ids, attention_mask)
            loss = model.compute_loss(logits, labels)
            
            total_loss += loss.item()
            
            # ì˜ˆì¸¡ ë° í™•ë¥  ê³„ì‚°
            if config.num_classes == 2:
                probs = torch.sigmoid(logits[:, 1] - logits[:, 0])
                preds = (probs > 0.5).long()
            else:
                probs = torch.softmax(logits, dim=-1)
                preds = torch.argmax(logits, dim=-1)
            
            # gradient ë¶„ë¦¬í•˜ì—¬ numpy ë³€í™˜
            all_preds.extend(preds.detach().cpu().numpy())
            all_labels.extend(labels.detach().cpu().numpy())
            
            # í™•ë¥  ì²˜ë¦¬ - gradient ë¶„ë¦¬ ë° ì˜ˆì™¸ ì²˜ë¦¬
            try:
                if config.num_classes == 2:
                    all_probs.extend(probs.detach().cpu().numpy())
                else:
                    all_probs.extend(probs[:, 1].detach().cpu().numpy())
            except Exception as e:
                print(f"âš ï¸ ê²€ì¦ í™•ë¥  ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
                # í´ë°±: sigmoid í™•ë¥  ì‚¬ìš©
                prob_values = torch.sigmoid(logits).detach().cpu().numpy()
                if len(prob_values.shape) > 1 and prob_values.shape[1] > 1:
                    all_probs.extend(prob_values[:, 1])
                else:
                    all_probs.extend(prob_values.flatten())
            all_languages.extend(languages)
    
    # ì „ì²´ ì§€í‘œ ê³„ì‚°
    overall_metrics = compute_metrics(
        np.array(all_labels),
        np.array(all_preds),
        np.array(all_probs)
    )
    overall_metrics['loss'] = total_loss / len(val_loader)
    
    # ì–¸ì–´ë³„ ì§€í‘œ ê³„ì‚°
    language_metrics = compute_language_specific_metrics(
        all_labels, all_preds, all_probs, all_languages
    )
    
    return overall_metrics, language_metrics

def compute_target_languages_avg_macro_f1(language_metrics: Dict[str, Dict[str, float]], 
                                          target_languages: List[str]) -> float:
    """íƒ€ê²Ÿ ì–¸ì–´ë“¤ì˜ í‰ê·  Macro F1 ê³„ì‚°"""
    
    valid_macro_f1s = []
    for lang in target_languages:
        if lang in language_metrics and 'macro_f1' in language_metrics[lang]:
            if language_metrics[lang]['macro_f1'] > 0:
                valid_macro_f1s.append(language_metrics[lang]['macro_f1'])
                print(f"  {lang} Macro F1: {language_metrics[lang]['macro_f1']:.4f}")
    
    if valid_macro_f1s:
        avg_macro_f1 = np.mean(valid_macro_f1s)
        print(f"  í‰ê·  Macro F1 ({len(valid_macro_f1s)}ê°œ ì–¸ì–´): {avg_macro_f1:.4f}")
        return avg_macro_f1
    else:
        print("  âš ï¸ ìœ íš¨í•œ ì–¸ì–´ë³„ Macro F1ê°€ ì—†ì–´ ì „ì²´ Macro F1 ì‚¬ìš©")
        return 0.0

def train_model(config: TextOnlyConfig) -> Tuple[nn.Module, str]:
    """ëª¨ë¸ í›ˆë ¨"""
    
    print("ğŸ”¥ Text-only (Gemma Encoder) ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    print(f"  ì–¸ì–´: {config.languages}")
    print(f"  í…ìŠ¤íŠ¸ ì¸ì½”ë”: {config.text_encoder}")
    print(f"  ë°°ì¹˜ í¬ê¸°: {config.batch_size}")
    print(f"  í•™ìŠµë¥ : {config.learning_rate}")
    print(f"  ì—í¬í¬: {config.num_epochs}")
    print(f"  Early Stopping: {config.early_stopping_patience} epochs")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = config.device
    print(f"  ë””ë°”ì´ìŠ¤: {device}")
    
    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(config.text_encoder)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    # ë°ì´í„°ë¡œë” ìƒì„±
    train_loader, val_loader, test_loader = create_dataloaders(
        config, mode="text_only", tokenizer=tokenizer
    )
    
    # ëª¨ë¸ ìƒì„±
    model = TextOnlyModel(config).to(device)
    
    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ë° ì ìš©
    if config.auto_class_weights:
        class_weights = compute_class_weights(train_loader.dataset, config)
        if hasattr(model.criterion, 'alpha'):
            model.criterion.alpha = torch.tensor(class_weights[1] / class_weights[0]).to(device)
    
    # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬
    optimizer = AdamW(model.parameters(), lr=config.learning_rate, weight_decay=0.01)
    scheduler = CosineAnnealingLR(optimizer, T_max=config.num_epochs)
    
    # Wandb ì´ˆê¸°í™”
    if config.log_wandb:
        wandb.init(
            project="dementia-prediction-control-groups",
            name=f"text-only-{'-'.join(config.languages)}-{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            config=config.__dict__
        )
    
    # í›ˆë ¨ ë£¨í”„
    best_metric = 0.0
    patience_counter = 0
    best_model_path = None
    
    for epoch in range(config.num_epochs):
        print(f"\n=== Epoch {epoch+1}/{config.num_epochs} ===")
        
        # í›ˆë ¨
        train_metrics = train_epoch(model, train_loader, optimizer, scheduler, device, config)
        print(f"í›ˆë ¨ - Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.4f}, "
              f"Macro F1: {train_metrics['macro_f1']:.4f}, AUC: {train_metrics['auc']:.4f}")
        
        # ê²€ì¦
        val_metrics, lang_metrics = validate_epoch(model, val_loader, device, config)
        print(f"ê²€ì¦ - Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.4f}, "
              f"Macro F1: {val_metrics['macro_f1']:.4f}, AUC: {val_metrics['auc']:.4f}")
        
        # ì–¸ì–´ë³„ ì„±ëŠ¥
        for lang, metrics in lang_metrics.items():
            print(f"  {lang} - Acc: {metrics['accuracy']:.4f}, Macro F1: {metrics['macro_f1']:.4f}, "
                  f"AUC: {metrics['auc']:.4f}")
        
        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ ê¸°ì¤€ ê³„ì‚°
        if config.best_model_metric == "avg_lang_macro_f1":
            current_metric = compute_target_languages_avg_macro_f1(lang_metrics, config.target_languages)
        else:
            current_metric = val_metrics['macro_f1']
        
        # Wandb ë¡œê¹…
        if config.log_wandb:
            log_dict = {
                'epoch': epoch + 1,
                'train_loss': train_metrics['loss'],
                'train_accuracy': train_metrics['accuracy'],
                'train_macro_f1': train_metrics['macro_f1'],
                'train_auc': train_metrics['auc'],
                'val_loss': val_metrics['loss'],
                'val_accuracy': val_metrics['accuracy'],
                'val_macro_f1': val_metrics['macro_f1'],
                'val_auc': val_metrics['auc'],
                'current_metric': current_metric
            }
            
            # ì–¸ì–´ë³„ ì§€í‘œ ì¶”ê°€
            for lang, metrics in lang_metrics.items():
                for metric_name, value in metrics.items():
                    log_dict[f'{lang}_{metric_name}'] = value
            
            wandb.log(log_dict)
        
        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥
        if current_metric > best_metric:
            best_metric = current_metric
            patience_counter = 0
            
            # ëª¨ë¸ ì €ì¥
            if config.save_checkpoints:
                os.makedirs(config.output_dir, exist_ok=True)
                best_model_path = os.path.join(config.output_dir, 'best_text_only_model.pth')
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'config': config.__dict__,
                    'epoch': epoch + 1,
                    'best_metric': best_metric,
                    'val_metrics': val_metrics,
                    'lang_metrics': lang_metrics
                }, best_model_path)
                print(f"âœ… ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥: {best_model_path}")
        else:
            patience_counter += 1
        
        # Early Stopping
        if patience_counter >= config.early_stopping_patience:
            print(f"ğŸ›‘ Early Stopping: {config.early_stopping_patience} epochs ë™ì•ˆ ì„±ëŠ¥ í–¥ìƒ ì—†ìŒ")
            break
    
    # ìµœì¢… í…ŒìŠ¤íŠ¸ (ìˆëŠ” ê²½ìš°)
    if test_loader and best_model_path:
        print("\n=== ìµœì¢… í…ŒìŠ¤íŠ¸ ===")
        model.load_state_dict(torch.load(best_model_path)['model_state_dict'])
        test_metrics, test_lang_metrics = validate_epoch(model, test_loader, device, config)
        
        print(f"í…ŒìŠ¤íŠ¸ - Acc: {test_metrics['accuracy']:.4f}, Macro F1: {test_metrics['macro_f1']:.4f}, "
              f"AUC: {test_metrics['auc']:.4f}")
        
        for lang, metrics in test_lang_metrics.items():
            print(f"  {lang} - Acc: {metrics['accuracy']:.4f}, Macro F1: {metrics['macro_f1']:.4f}, "
                  f"AUC: {metrics['auc']:.4f}")
        
        if config.log_wandb:
            test_log_dict = {'test_accuracy': test_metrics['accuracy'],
                           'test_macro_f1': test_metrics['macro_f1'],
                           'test_auc': test_metrics['auc']}
            
            for lang, metrics in test_lang_metrics.items():
                for metric_name, value in metrics.items():
                    test_log_dict[f'test_{lang}_{metric_name}'] = value
            
            wandb.log(test_log_dict)
    
    if config.log_wandb:
        wandb.finish()
    
    print(f"\nâœ… Text-only ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ! ë² ìŠ¤íŠ¸ {config.best_model_metric}: {best_metric:.4f}")
    return model, best_model_path

def main():
    parser = argparse.ArgumentParser(description="Text-only Model Training")
    
    # ë°ì´í„° ê´€ë ¨
    parser.add_argument('--data_dir', type=str, default='../../training_dset', help='ë°ì´í„° ë””ë ‰í† ë¦¬')
    parser.add_argument('--languages', nargs='+', default=['English', 'Mandarin'], help='ì‚¬ìš©í•  ì–¸ì–´')
    
    # í›ˆë ¨ ê´€ë ¨
    parser.add_argument('--batch_size', type=int, default=64, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--learning_rate', type=float, default=2e-5, help='í•™ìŠµë¥ ')
    parser.add_argument('--num_epochs', type=int, default=100, help='ì—í¬í¬ ìˆ˜')
    parser.add_argument('--early_stopping_patience', type=int, default=10, help='Early stopping patience')
    
    # ëª¨ë¸ ê´€ë ¨
    parser.add_argument('--text_encoder', type=str, default='google/gemma-2b', help='í…ìŠ¤íŠ¸ ì¸ì½”ë” ëª¨ë¸ëª…')
    parser.add_argument('--use_cls_token', action='store_true', help='[CLS] í† í° ì‚¬ìš©')
    
    # ì†ì‹¤ í•¨ìˆ˜ ê´€ë ¨
    parser.add_argument('--loss_type', type=str, default='focal', choices=['focal', 'bce'], help='ì†ì‹¤ í•¨ìˆ˜')
    parser.add_argument('--focal_alpha', type=float, default=1.0, help='Focal loss alpha')
    parser.add_argument('--focal_gamma', type=float, default=2.0, help='Focal loss gamma')
    parser.add_argument('--auto_class_weights', action='store_true', help='ìë™ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜')
    
    # í‰ê°€ ê´€ë ¨
    parser.add_argument('--best_model_metric', type=str, default='avg_lang_macro_f1', 
                       choices=['val_macro_f1', 'avg_lang_macro_f1'], help='ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ ê¸°ì¤€')
    parser.add_argument('--target_languages', nargs='+', help='íƒ€ê²Ÿ ì–¸ì–´ (í‰ê·  ê³„ì‚°ìš©)')
    parser.add_argument('--split_by_patient', type=str, default='true', choices=['true', 'false'], 
                       help='í™˜ì ë‹¨ìœ„ ë¶„í•  ì—¬ë¶€')
    
    # ì¶œë ¥ ê´€ë ¨
    parser.add_argument('--output_dir', type=str, default='../modules/outputs/controlgroups', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--no_wandb', action='store_true', help='Wandb ë¹„í™œì„±í™”')
    
    args = parser.parse_args()
    
    # ì„¤ì • ìƒì„±
    config = TextOnlyConfig(
        data_dir=args.data_dir,
        languages=args.languages,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        num_epochs=args.num_epochs,
        early_stopping_patience=args.early_stopping_patience,
        text_encoder=args.text_encoder,
        use_cls_token=args.use_cls_token,
        loss_type=args.loss_type,
        focal_alpha=args.focal_alpha,
        focal_gamma=args.focal_gamma,
        auto_class_weights=args.auto_class_weights,
        best_model_metric=args.best_model_metric,
        target_languages=args.target_languages or args.languages,
        split_by_patient=(args.split_by_patient.lower() == 'true'),
        output_dir=args.output_dir,
        log_wandb=(not args.no_wandb)
    )
    
    # í›ˆë ¨ ì‹¤í–‰
    train_model(config)

if __name__ == "__main__":
    main()
