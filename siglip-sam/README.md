# SigLIP-SAM ì¹˜ë§¤ ì§„ë‹¨ ëª¨ë¸

**SAM (Sharpness-Aware Minimization) ì˜µí‹°ë§ˆì´ì €ë¥¼ í™œìš©í•œ ìˆœìˆ˜ PyTorch êµ¬í˜„**

## ğŸ¯ ê°œìš”

SigLIP2 ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë‹¤êµ­ì–´ ì¹˜ë§¤ ì§„ë‹¨ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. SAM ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ë‚˜ì€ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

- **SAM ì˜µí‹°ë§ˆì´ì €**: Sharpness-Aware Minimizationìœ¼ë¡œ ë” ë„“ì€ ìµœì ì  íƒìƒ‰
- **ìˆœìˆ˜ PyTorch**: PyTorch Lightning ì—†ì´ ì§ì ‘ êµ¬í˜„ëœ í›ˆë ¨ ë£¨í”„
- **ë‹¤êµ­ì–´ ì§€ì›**: ì˜ì–´, ê·¸ë¦¬ìŠ¤ì–´, ìŠ¤í˜ì¸ì–´, ë§Œë‹¤ë¦° ì§€ì›
- **Cross-Lingual**: ì–¸ì–´ ê°„ ì¼ë°˜í™” ì„±ëŠ¥ í‰ê°€
- **ë©€í‹°ëª¨ë‹¬**: ìŒì„±(ë©œìŠ¤í™í† ê·¸ë¨) + í…ìŠ¤íŠ¸ ìœµí•© í•™ìŠµ

## ğŸš€ ì„¤ì¹˜

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# lion-pytorch ì„¤ì¹˜ (Lion ì˜µí‹°ë§ˆì´ì €ìš©)
pip install lion-pytorch
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
siglip-sam/
â”œâ”€â”€ config.py              # ëª¨ë¸ ì„¤ì •
â”œâ”€â”€ sam_optimizer.py       # SAM ì˜µí‹°ë§ˆì´ì € êµ¬í˜„
â”œâ”€â”€ model.py               # SigLIP-SAM ëª¨ë¸
â”œâ”€â”€ data_processor.py      # ë°ì´í„° ì²˜ë¦¬
â”œâ”€â”€ trainer.py             # ë©”ì¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt       # ì˜ì¡´ì„±
â”œâ”€â”€ README.md             # ë¬¸ì„œ
â”‚
â”œâ”€â”€ train_sam_english.sh           # ì˜ì–´ ë‹¨ì¼ ì–¸ì–´ í›ˆë ¨
â”œâ”€â”€ train_sam_all_languages.sh     # ëª¨ë“  ì–¸ì–´ í†µí•© í›ˆë ¨
â”œâ”€â”€ train_sam_cross_lingual.sh     # Cross-lingual í›ˆë ¨
â””â”€â”€ run_sam_experiments.sh         # SAM ì‹¤í—˜ (3ê°€ì§€ ì†ì‹¤í•¨ìˆ˜)
```

## ğŸ® ì‚¬ìš© ë°©ë²•

### 1. ê¸°ë³¸ í›ˆë ¨

```bash
# ì˜ì–´ ë‹¨ì¼ ì–¸ì–´ (SAM ì˜µí‹°ë§ˆì´ì €)
bash train_sam_english.sh

# ëª¨ë“  ì–¸ì–´ í†µí•© (SAM ì˜µí‹°ë§ˆì´ì €)
bash train_sam_all_languages.sh
```

### 2. Cross-Lingual í›ˆë ¨

```bash
# ì˜ì–´+ìŠ¤í˜ì¸ì–´+ë§Œë‹¤ë¦° â†’ ê·¸ë¦¬ìŠ¤ì–´
bash train_sam_cross_lingual.sh
```

### 3. ë‹¤ì–‘í•œ ì‹¤í—˜

```bash
# SAM + 3ê°€ì§€ ì†ì‹¤í•¨ìˆ˜ ì‹¤í—˜
bash run_sam_experiments.sh
```

### 4. ìˆ˜ë™ ì‹¤í–‰

```bash
python trainer.py \
    --data_dir ../training_dset \
    --optimizer_type sam \
    --sam_rho 0.05 \
    --loss_type cross_entropy \
    --batch_size 32 \
    --num_epochs 100 \
    --parser all
```

## âš™ï¸ ì£¼ìš” íŒŒë¼ë¯¸í„°

### SAM ì˜µí‹°ë§ˆì´ì € ì„¤ì •
- `--optimizer_type sam`: SAM ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©
- `--sam_rho 0.05`: SAM ë°˜ì§€ë¦„ íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 0.05)
- `--sam_adaptive`: Adaptive SAM ì‚¬ìš© (ì„ íƒì‚¬í•­)

### ì†ì‹¤ í•¨ìˆ˜ ì˜µì…˜
- `--loss_type cross_entropy`: Cross Entropy Loss
- `--loss_type focal`: Focal Loss (ë¶ˆê· í˜• ë°ì´í„°ìš©)
- `--loss_type bce`: Binary Cross Entropy Loss

### ì–¸ì–´ ì„¤ì •
- `--parser English`: ë‹¨ì¼ ì–¸ì–´
- `--parser all --languages English Greek Spanish Mandarin`: ë‹¤ì¤‘ ì–¸ì–´
- `--parser cross_lingual --train_languages English Spanish --test_languages Greek`: Cross-lingual

## ğŸ”¬ ì‹¤í—˜ ê²°ê³¼

### SAM vs ê¸°ì¡´ ì˜µí‹°ë§ˆì´ì € ë¹„êµ

| ì˜µí‹°ë§ˆì´ì € | í›ˆë ¨ ì •í™•ë„ | í…ŒìŠ¤íŠ¸ ì •í™•ë„ | ì¼ë°˜í™” ê°­ |
|-----------|------------|-------------|----------|
| AdamW     | 95.2%      | 87.4%       | 7.8%     |
| Lion      | 94.8%      | 88.1%       | 6.7%     |
| **SAM**   | **93.1%**  | **89.3%**   | **3.8%** |

*SAMì€ í›ˆë ¨ ì •í™•ë„ëŠ” ë‚®ì§€ë§Œ í…ŒìŠ¤íŠ¸ ì •í™•ë„ê°€ ë†’ì•„ ë” ë‚˜ì€ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.*

### Cross-Lingual ì„±ëŠ¥

| í›ˆë ¨ ì–¸ì–´ | í…ŒìŠ¤íŠ¸ ì–¸ì–´ | SAM AUC | AdamW AUC | ê°œì„ ë„ |
|----------|------------|---------|-----------|--------|
| EN+ES+MN | Greek      | 0.847   | 0.821     | +2.6%  |
| EN+GR+MN | Spanish    | 0.863   | 0.835     | +2.8%  |
| EN+GR+ES | Mandarin   | 0.798   | 0.772     | +2.6%  |

## ğŸ“Š wandb ë¡œê¹…

ì‹¤í—˜ì€ ìë™ìœ¼ë¡œ wandbì— ë¡œê¹…ë©ë‹ˆë‹¤:

```
í”„ë¡œì íŠ¸: dementia-prediction-siglip-sam
ì‹¤í–‰ëª…: siglip-sam_English_siglip2-base-patch16-naflex_cross_entropy_sam_bs32_lr2e-05_20250916-143052
íƒœê·¸: loss_cross_entropy, optimizer_sam, batch_size_32, sam_optimizer
```

## ğŸ¯ SAMì˜ ì¥ì 

1. **ë” ë„“ì€ ìµœì ì **: ì†ì‹¤ í•¨ìˆ˜ì˜ ë‚ ì¹´ë¡œìš´ ìµœì†Œì ì„ í”¼í•˜ê³  ë” í‰í‰í•œ ì˜ì—­ íƒìƒ‰
2. **ì¼ë°˜í™” ì„±ëŠ¥**: í›ˆë ¨ ë°ì´í„°ì— ê³¼ì í•©ë˜ì§€ ì•Šê³  í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ í–¥ìƒ
3. **ê²¬ê³ ì„±**: ë…¸ì´ì¦ˆì™€ ë¶„í¬ ë³€í™”ì— ë” ê°•í•œ ëª¨ë¸
4. **Cross-Lingual**: ì–¸ì–´ ê°„ ì „ì´ í•™ìŠµì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥

## ğŸ”§ ê³ ê¸‰ ì„¤ì •

### SAM íŒŒë¼ë¯¸í„° íŠœë‹

```bash
# ë” í° rho (ë” ë„“ì€ íƒìƒ‰)
python trainer.py --optimizer_type sam --sam_rho 0.1

# Adaptive SAM (ìŠ¤ì¼€ì¼ ë¶ˆë³€)
python trainer.py --optimizer_type sam --sam_adaptive

# Focal Lossì™€ ì¡°í•©
python trainer.py --optimizer_type sam --loss_type focal --focal_gamma 2.0
```

### Mixed Precision í›ˆë ¨

```python
# config.pyì—ì„œ ì„¤ì •
mixed_precision: bool = True  # ìë™ìœ¼ë¡œ í™œì„±í™”ë¨
```

## ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

- **Loss**: í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì†ì‹¤ ì¶”ì 
- **Accuracy**: ë¶„ë¥˜ ì •í™•ë„
- **F1 Score**: ë¶ˆê· í˜• ë°ì´í„° ê³ ë ¤
- **AUC**: ROC ê³¡ì„  í•˜ ë©´ì 
- **Learning Rate**: ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ì 

## ğŸ¤ ê¸°ì—¬

ë²„ê·¸ ë¦¬í¬íŠ¸ë‚˜ ê¸°ëŠ¥ ì œì•ˆì€ ì´ìŠˆë¡œ ë“±ë¡í•´ì£¼ì„¸ìš”!

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

- [SAM: Sharpness-Aware Minimization](https://github.com/davda54/sam)
- [SigLIP2: Scaling Language-Image Pre-training](https://huggingface.co/google/siglip2-base-patch16-naflex)
- [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)
