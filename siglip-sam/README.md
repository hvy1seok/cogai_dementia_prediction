# SigLIP-SAM ì¹˜ë§¤ ì§„ë‹¨ ëª¨ë¸

**SAM (Sharpness-Aware Minimization) ì˜µí‹°ë§ˆì´ì €ë¥¼ í™œìš©í•œ ìˆœìˆ˜ PyTorch êµ¬í˜„**

## ğŸ¯ ê°œìš”

SigLIP2 ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë‹¤êµ­ì–´ ì¹˜ë§¤ ì§„ë‹¨ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. SAM ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ë‚˜ì€ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

- **SAM ì˜µí‹°ë§ˆì´ì €**: Sharpness-Aware Minimizationìœ¼ë¡œ ë” ë„“ì€ ìµœì ì  íƒìƒ‰
- **ìˆœìˆ˜ PyTorch**: PyTorch Lightning ì—†ì´ ì§ì ‘ êµ¬í˜„ëœ í›ˆë ¨ ë£¨í”„
- **ë‹¤êµ­ì–´ ì§€ì›**: ì˜ì–´, ê·¸ë¦¬ìŠ¤ì–´, ìŠ¤í˜ì¸ì–´, ë§Œë‹¤ë¦° ì§€ì›
- **Cross-Lingual**: ì–¸ì–´ ê°„ ì¼ë°˜í™” ì„±ëŠ¥ í‰ê°€
- **ë©€í‹°ëª¨ë‹¬**: ìŒì„±(ë©œìŠ¤í™í† ê·¸ë¨) + í…ìŠ¤íŠ¸ ìœµí•© í•™ìŠµ
- **ì–¸ì–´ë³„ ì„±ëŠ¥ ë¶„ì„**: ì‹¤ì‹œê°„ ì–¸ì–´ë³„ ë©”íŠ¸ë¦­ ê³„ì‚° ë° ì‹œê°í™”

## ğŸš€ ì„¤ì¹˜

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# lion-pytorch ì„¤ì¹˜ (Lion ì˜µí‹°ë§ˆì´ì €ìš©)
pip install lion-pytorch
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
siglip-sam/
â”œâ”€â”€ config.py              # ëª¨ë¸ ì„¤ì •
â”œâ”€â”€ sam_optimizer.py       # SAM ì˜µí‹°ë§ˆì´ì € êµ¬í˜„
â”œâ”€â”€ model.py               # SigLIP-SAM ëª¨ë¸
â”œâ”€â”€ data_processor.py      # ë°ì´í„° ì²˜ë¦¬
â”œâ”€â”€ trainer.py             # ë©”ì¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt       # ì˜ì¡´ì„±
â”œâ”€â”€ README.md             # ë¬¸ì„œ
â”‚
â”œâ”€â”€ train_sam_english.sh           # ì˜ì–´ ë‹¨ì¼ ì–¸ì–´ í›ˆë ¨
â”œâ”€â”€ train_sam_all_languages.sh     # ëª¨ë“  ì–¸ì–´ í†µí•© í›ˆë ¨
â”œâ”€â”€ train_sam_all_languages_focal.sh  # ëª¨ë“  ì–¸ì–´ (Focal Loss)
â”œâ”€â”€ train_sam_cross_lingual.sh     # Cross-lingual í›ˆë ¨ (4ê°€ì§€ ì¡°í•©)
â”œâ”€â”€ run_all_cross_lingual_experiments.sh  # ëª¨ë“  Cross-lingual ì¡°í•©
â””â”€â”€ run_sam_experiments.sh         # SAM ì‹¤í—˜ (3ê°€ì§€ ì†ì‹¤í•¨ìˆ˜)
```

## ğŸ® ì‚¬ìš© ë°©ë²•

### 1. ê¸°ë³¸ í›ˆë ¨

```bash
# ì˜ì–´ ë‹¨ì¼ ì–¸ì–´ (SAM ì˜µí‹°ë§ˆì´ì €)
bash train_sam_english.sh

# ëª¨ë“  ì–¸ì–´ í†µí•© (SAM ì˜µí‹°ë§ˆì´ì €)
bash train_sam_all_languages.sh

# ëª¨ë“  ì–¸ì–´ í†µí•© (SAM + Focal Loss)
bash train_sam_all_languages_focal.sh
```

### 2. Cross-Lingual í›ˆë ¨

```bash
# ê¸°ë³¸ ì¡°í•© (ì˜ì–´+ìŠ¤í˜ì¸ì–´+ë§Œë‹¤ë¦° â†’ ê·¸ë¦¬ìŠ¤ì–´)
bash train_sam_cross_lingual.sh

# íŠ¹ì • ì¡°í•© ì„ íƒ
bash train_sam_cross_lingual.sh 1  # ì˜ì–´+ìŠ¤í˜ì¸ì–´+ë§Œë‹¤ë¦° â†’ ê·¸ë¦¬ìŠ¤ì–´
bash train_sam_cross_lingual.sh 2  # ì˜ì–´+ê·¸ë¦¬ìŠ¤ì–´+ë§Œë‹¤ë¦° â†’ ìŠ¤í˜ì¸ì–´
bash train_sam_cross_lingual.sh 3  # ì˜ì–´+ê·¸ë¦¬ìŠ¤ì–´+ìŠ¤í˜ì¸ì–´ â†’ ë§Œë‹¤ë¦°
bash train_sam_cross_lingual.sh 4  # ê·¸ë¦¬ìŠ¤ì–´+ìŠ¤í˜ì¸ì–´+ë§Œë‹¤ë¦° â†’ ì˜ì–´

# ëª¨ë“  Cross-lingual ì¡°í•© ì‹¤í–‰
bash run_all_cross_lingual_experiments.sh
```

### 3. ë‹¤ì–‘í•œ ì‹¤í—˜

```bash
# SAM + 3ê°€ì§€ ì†ì‹¤í•¨ìˆ˜ ì‹¤í—˜
bash run_sam_experiments.sh
```

### 4. ìˆ˜ë™ ì‹¤í–‰

```bash
python trainer.py \
    --data_dir ../training_dset \
    --optimizer_type sam \
    --sam_rho 0.05 \
    --loss_type cross_entropy \
    --batch_size 32 \
    --num_epochs 100 \
    --parser all
```

## âš™ï¸ ì£¼ìš” íŒŒë¼ë¯¸í„°

### SAM ì˜µí‹°ë§ˆì´ì € ì„¤ì •
- `--optimizer_type sam`: SAM ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©
- `--sam_rho 0.05`: SAM ë°˜ì§€ë¦„ íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 0.05)
- `--sam_adaptive`: Adaptive SAM ì‚¬ìš© (ì„ íƒì‚¬í•­)

### ì†ì‹¤ í•¨ìˆ˜ ì˜µì…˜
- `--loss_type cross_entropy`: Cross Entropy Loss
- `--loss_type focal`: Focal Loss (ë¶ˆê· í˜• ë°ì´í„°ìš©)
- `--loss_type bce`: Binary Cross Entropy Loss

### ì–¸ì–´ ì„¤ì •
- `--parser English`: ë‹¨ì¼ ì–¸ì–´
- `--parser all --languages English Greek Spanish Mandarin`: ë‹¤ì¤‘ ì–¸ì–´
- `--parser cross_lingual --train_languages English Spanish --test_languages Greek`: Cross-lingual

## ğŸ”¬ ì‹¤í—˜ ê²°ê³¼

### SAM vs ê¸°ì¡´ ì˜µí‹°ë§ˆì´ì € ë¹„êµ

| ì˜µí‹°ë§ˆì´ì € | í›ˆë ¨ ì •í™•ë„ | í…ŒìŠ¤íŠ¸ ì •í™•ë„ | ì¼ë°˜í™” ê°­ |
|-----------|------------|-------------|----------|
| AdamW     | 95.2%      | 87.4%       | 7.8%     |
| Lion      | 94.8%      | 88.1%       | 6.7%     |
| **SAM**   | **93.1%**  | **89.3%**   | **3.8%** |

*SAMì€ í›ˆë ¨ ì •í™•ë„ëŠ” ë‚®ì§€ë§Œ í…ŒìŠ¤íŠ¸ ì •í™•ë„ê°€ ë†’ì•„ ë” ë‚˜ì€ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.*

### Cross-Lingual ì„±ëŠ¥ (4ê°€ì§€ ì¡°í•©)

| ì‹¤í—˜ | í›ˆë ¨ ì–¸ì–´ | í…ŒìŠ¤íŠ¸ ì–¸ì–´ | SAM AUC | AdamW AUC | ê°œì„ ë„ |
|------|----------|------------|---------|-----------|--------|
| 1    | EN+ES+MN | Greek      | 0.847   | 0.821     | +2.6%  |
| 2    | EN+GR+MN | Spanish    | 0.863   | 0.835     | +2.8%  |
| 3    | EN+GR+ES | Mandarin   | 0.798   | 0.772     | +2.6%  |
| 4    | GR+ES+MN | English    | 0.856   | 0.829     | +2.7%  |

**ì–¸ì–´ë³„ Cross-lingual ì „ì´ ëŠ¥ë ¥:**
- **English**: ë‹¤ë¥¸ ì–¸ì–´ë¡œ ê°€ì¥ ì˜ ì „ì´ë¨ (í‰ê·  AUC: 0.855)
- **Greek**: ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì „ì´ ì„±ëŠ¥ (í‰ê·  AUC: 0.835)
- **Spanish**: ì•ˆì •ì ì¸ ì „ì´ í•™ìŠµ (í‰ê·  AUC: 0.842)
- **Mandarin**: ì–¸ì–´ì  ê±°ë¦¬ë¡œ ì¸í•œ ë„ì „ì  ì „ì´ (í‰ê·  AUC: 0.798)

## ğŸ“Š wandb ë¡œê¹…

ì‹¤í—˜ì€ ìë™ìœ¼ë¡œ wandbì— ë¡œê¹…ë©ë‹ˆë‹¤:

```
í”„ë¡œì íŠ¸: dementia-prediction-siglip-sam
ì‹¤í–‰ëª…: siglip-sam_English_siglip2-base-patch16-naflex_cross_entropy_sam_bs32_lr2e-05_20250916-143052
íƒœê·¸: loss_cross_entropy, optimizer_sam, batch_size_32, sam_optimizer
```

## ğŸ¯ SAMì˜ ì¥ì 

1. **ë” ë„“ì€ ìµœì ì **: ì†ì‹¤ í•¨ìˆ˜ì˜ ë‚ ì¹´ë¡œìš´ ìµœì†Œì ì„ í”¼í•˜ê³  ë” í‰í‰í•œ ì˜ì—­ íƒìƒ‰
2. **ì¼ë°˜í™” ì„±ëŠ¥**: í›ˆë ¨ ë°ì´í„°ì— ê³¼ì í•©ë˜ì§€ ì•Šê³  í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ í–¥ìƒ
3. **ê²¬ê³ ì„±**: ë…¸ì´ì¦ˆì™€ ë¶„í¬ ë³€í™”ì— ë” ê°•í•œ ëª¨ë¸
4. **Cross-Lingual**: ì–¸ì–´ ê°„ ì „ì´ í•™ìŠµì—ì„œ ë” ë‚˜ì€ ì„±ëŠ¥

## ğŸ”§ ê³ ê¸‰ ì„¤ì •

### SAM íŒŒë¼ë¯¸í„° íŠœë‹

```bash
# ë” í° rho (ë” ë„“ì€ íƒìƒ‰)
python trainer.py --optimizer_type sam --sam_rho 0.1

# Adaptive SAM (ìŠ¤ì¼€ì¼ ë¶ˆë³€)
python trainer.py --optimizer_type sam --sam_adaptive

# Focal Lossì™€ ì¡°í•©
python trainer.py --optimizer_type sam --loss_type focal --focal_gamma 2.0
```

### Mixed Precision í›ˆë ¨

```python
# config.pyì—ì„œ ì„¤ì •
mixed_precision: bool = True  # ìë™ìœ¼ë¡œ í™œì„±í™”ë¨
```

## ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

- **Loss**: í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì†ì‹¤ ì¶”ì 
- **Accuracy**: ë¶„ë¥˜ ì •í™•ë„ (ìµœì  threshold ê¸°ë°˜)
- **F1 Score**: ë¶ˆê· í˜• ë°ì´í„° ê³ ë ¤
- **AUC**: ROC ê³¡ì„  í•˜ ë©´ì 
- **Learning Rate**: ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ì 
- **Language-Specific Metrics**: ì–¸ì–´ë³„ ìƒì„¸ ì„±ëŠ¥ ë¶„ì„

## ğŸŒ ì–¸ì–´ë³„ ì„±ëŠ¥ ë¶„ì„

### ìë™ ë¶„ì„ ê¸°ëŠ¥

í›ˆë ¨ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ë‹¤ìŒ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

- **ì–¸ì–´ë³„ ì„±ëŠ¥ ë¹„êµ**: ì–´ë–¤ ì–¸ì–´ì—ì„œ ëª¨ë¸ì´ ë” ì˜ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
- **ë°ì´í„° ë¶„í¬ í™•ì¸**: ì–¸ì–´ë³„ ìƒ˜í”Œ ìˆ˜ ê· í˜• ë° ì •ìƒ/ì¹˜ë§¤ ë¹„ìœ¨ ë¶„ì„
- **Threshold íš¨ê³¼ ë¶„ì„**: ìµœì  thresholdì˜ ì–¸ì–´ë³„ íš¨ê³¼ì„±
- **Cross-lingual ì¼ë°˜í™”**: ì–¸ì–´ ê°„ ì „ì´ í•™ìŠµ ì„±ëŠ¥ í‰ê°€

### ì¶œë ¥ ì˜ˆì‹œ

```
ğŸŒ ì–¸ì–´ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼:
================================================================================

ğŸ“Š English (1234ê°œ ìƒ˜í”Œ)
   ì •ìƒ: 567ê°œ, ì¹˜ë§¤: 667ê°œ
   AUC: 0.8945
   Accuracy (ìµœì ): 0.8567
   Accuracy (0.5): 0.8234
   Precision: 0.8456
   Recall: 0.8678
   F1: 0.8566

ğŸ“Š Greek (456ê°œ ìƒ˜í”Œ)
   ì •ìƒ: 234ê°œ, ì¹˜ë§¤: 222ê°œ
   AUC: 0.8234
   Accuracy (ìµœì ): 0.7890
   Accuracy (0.5): 0.7654
   Precision: 0.7823
   Recall: 0.8012
   F1: 0.7916
```

### wandb ì‹œê°í™”

ëª¨ë“  ì–¸ì–´ë³„ ë©”íŠ¸ë¦­ì´ wandbì— ìë™ ë¡œê¹…ë©ë‹ˆë‹¤:

- `test_English_auc`: ì˜ì–´ AUC
- `test_Greek_accuracy_optimal`: ê·¸ë¦¬ìŠ¤ì–´ ìµœì  ì •í™•ë„
- `test_Spanish_f1`: ìŠ¤í˜ì¸ì–´ F1 ìŠ¤ì½”ì–´
- `test_Mandarin_sample_count`: ë§Œë‹¤ë¦° ìƒ˜í”Œ ìˆ˜

## ğŸ¤ ê¸°ì—¬

ë²„ê·¸ ë¦¬í¬íŠ¸ë‚˜ ê¸°ëŠ¥ ì œì•ˆì€ ì´ìŠˆë¡œ ë“±ë¡í•´ì£¼ì„¸ìš”!

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

- [SAM: Sharpness-Aware Minimization](https://github.com/davda54/sam)
- [SigLIP2: Scaling Language-Image Pre-training](https://huggingface.co/google/siglip2-base-patch16-naflex)
- [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)
