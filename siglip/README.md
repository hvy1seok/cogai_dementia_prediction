# SigLIP2 ê¸°ë°˜ ì–¸ì–´ ë¬´ê´€ ì¹˜ë§¤ ì§„ë‹¨ ì‹œìŠ¤í…œ

ì´ í”„ë¡œì íŠ¸ëŠ” Googleì˜ SigLIP2 ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì–¸ì–´ì— êµ¬ì• ë°›ì§€ ì•ŠëŠ” ì¹˜ë§¤ ì§„ë‹¨ ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤. ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë©œìŠ¤í™í† ê·¸ë¨ìœ¼ë¡œ ë³€í™˜í•˜ê³  í…ìŠ¤íŠ¸ ì „ì‚¬ë³¸ê³¼ í•¨ê»˜ ë©€í‹°ëª¨ë‹¬ í•™ìŠµì„ í†µí•´ ì¹˜ë§¤ë¥¼ ì§„ë‹¨í•©ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” íŠ¹ì§•

- **ì–¸ì–´ ë¬´ê´€ í•™ìŠµ**: ë‹¤ì–‘í•œ ì–¸ì–´(ì˜ì–´, ê·¸ë¦¬ìŠ¤ì–´, í•œêµ­ì–´, ìŠ¤í˜ì¸ì–´, í”„ë‘ìŠ¤ì–´ ë“±)ì˜ ë°ì´í„°ë¡œ í•™ìŠµ
- **ë©€í‹°ëª¨ë‹¬ ì ‘ê·¼**: ì˜¤ë””ì˜¤(ë©œìŠ¤í™í† ê·¸ë¨) + í…ìŠ¤íŠ¸ ì „ì‚¬ë³¸ì„ ë™ì‹œì— í™œìš©
- **PyTorch Lightning**: ì²´ê³„ì ì¸ í›ˆë ¨ ê´€ë¦¬ ë° ì‹¤í—˜ ì¶”ì 
- **wandb í†µí•©**: ì‹¤ì‹œê°„ ì‹¤í—˜ ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
- **íš¨ìœ¨ì ì¸ ì¶”ë¡ **: í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¹ ë¥¸ ì˜ˆì¸¡

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
siglip/
â”œâ”€â”€ config.py              # ì„¤ì • íŒŒì¼
â”œâ”€â”€ data_processor.py      # ë°ì´í„° ì²˜ë¦¬ ë° ì „ì²˜ë¦¬
â”œâ”€â”€ model.py              # SigLIP2 ê¸°ë°˜ ëª¨ë¸ ì •ì˜
â”œâ”€â”€ trainer.py            # PyTorch Lightning í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ inference.py          # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt      # ì˜ì¡´ì„± íŒ¨í‚¤ì§€
â””â”€â”€ README.md            # ì´ íŒŒì¼
```

## ğŸ› ï¸ ì„¤ì¹˜

1. ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜:
```bash
pip install -r requirements.txt
```

2. wandb ë¡œê·¸ì¸ (ì„ íƒì‚¬í•­):
```bash
wandb login
```

## ğŸ“Š ë°ì´í„° í˜•ì‹

ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ì¤€ë¹„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤:

```
dementia_fulldata/
â”œâ”€â”€ English/
â”‚   â”œâ”€â”€ metadata.csv
â”‚   â”œâ”€â”€ audio1.wav
â”‚   â”œâ”€â”€ audio2.wav
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Greek/
â”‚   â”œâ”€â”€ metadata.txt
â”‚   â”œâ”€â”€ audio1.wav
â”‚   â””â”€â”€ ...
â””â”€â”€ Korean/
    â”œâ”€â”€ metadata.csv
    â””â”€â”€ ...
```

### ë©”íƒ€ë°ì´í„° íŒŒì¼ í˜•ì‹

**CSV í˜•ì‹:**
```csv
audio_file,transcript,dementia
audio1.wav,"Hello, how are you today?",0
audio2.wav,"I don't remember what I was saying...",1
```

**í…ìŠ¤íŠ¸ í˜•ì‹ (íƒ­ìœ¼ë¡œ êµ¬ë¶„):**
```
audio1.wav	Hello, how are you today?	0
audio2.wav	I don't remember what I was saying...	1
```

- `audio_file`: ì˜¤ë””ì˜¤ íŒŒì¼ëª…
- `transcript`: í…ìŠ¤íŠ¸ ì „ì‚¬ë³¸
- `dementia`: ë¼ë²¨ (0: ì •ìƒ, 1: ì¹˜ë§¤)

## ğŸš€ ì‚¬ìš©ë²•

### 1. ë°ì´í„° íŒŒì„œ í…ŒìŠ¤íŠ¸ (ê¶Œì¥)

ë¨¼ì € ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸:
```bash
python test_parser.py
```

### 2. ëª¨ë¸ í›ˆë ¨

#### ëŒ€í™”í˜• í›ˆë ¨ (ê¶Œì¥):
```bash
python run_siglip_training.py
```

#### ì§ì ‘ í›ˆë ¨:
ê¸°ë³¸ í›ˆë ¨ (ëª¨ë“  ì–¸ì–´):
```bash
python trainer.py --data_dir ../training_dset
```

íŠ¹ì • ì–¸ì–´ë§Œ í›ˆë ¨:
```bash
python trainer.py \
    --data_dir ../training_dset \
    --parser English
```

ê³ ê¸‰ ì˜µì…˜:
```bash
python trainer.py \
    --data_dir ../training_dset \
    --model_name google/siglip2-base-patch16-224 \
    --batch_size 8 \
    --learning_rate 2e-5 \
    --num_epochs 5 \
    --parser all
```

### 3. ì¶”ë¡ 

ë‹¨ì¼ ì˜ˆì¸¡:
```bash
python inference.py \
    --model_path ../modules/outputs/siglip/checkpoints/best_model.ckpt \
    --audio_path path/to/audio.wav \
    --text "Hello, how are you today?" \
    --language English
```

ë°°ì¹˜ ì˜ˆì¸¡:
```bash
python inference.py \
    --model_path ../modules/outputs/siglip/checkpoints/best_model.ckpt \
    --batch_file batch_data.json \
    --output predictions.json
```

ë°°ì¹˜ ë°ì´í„° JSON í˜•ì‹:
```json
[
    {
        "audio_path": "path/to/audio1.wav",
        "text": "Hello, how are you today?",
        "language": "English"
    },
    {
        "audio_path": "path/to/audio2.wav",
        "text": "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?",
        "language": "Korean"
    }
]
```

## âš™ï¸ ì„¤ì •

`config.py`ì—ì„œ ë‹¤ìŒ ì„¤ì •ë“¤ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

### ëª¨ë¸ ì„¤ì •
- `model_name`: SigLIP2 ëª¨ë¸ ë²„ì „
- `max_length`: í…ìŠ¤íŠ¸ ìµœëŒ€ ê¸¸ì´
- `image_size`: ë©œìŠ¤í™í† ê·¸ë¨ ì´ë¯¸ì§€ í¬ê¸°

### ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì„¤ì •
- `sample_rate`: ìƒ˜í”Œë§ ë ˆì´íŠ¸
- `n_mels`: ë©œ ìŠ¤ì¼€ì¼ ë¹ˆ ìˆ˜
- `n_fft`: FFT ìœˆë„ìš° í¬ê¸°
- `hop_length`: í™‰ ê¸¸ì´

### í›ˆë ¨ ì„¤ì •
- `batch_size`: ë°°ì¹˜ í¬ê¸°
- `learning_rate`: í•™ìŠµë¥ 
- `num_epochs`: ì—í¬í¬ ìˆ˜
- `weight_decay`: ê°€ì¤‘ì¹˜ ê°ì‡ 

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§

í›ˆë ¨ ì¤‘ì—ëŠ” wandbë¥¼ í†µí•´ ë‹¤ìŒ ë©”íŠ¸ë¦­ë“¤ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **í›ˆë ¨ ë©”íŠ¸ë¦­**: `train_loss`, `train_acc`
- **ê²€ì¦ ë©”íŠ¸ë¦­**: `val_loss`, `val_acc`, `val_f1`, `val_precision`, `val_recall`, `val_auc`
- **í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­**: `test_accuracy`, `test_f1`, `test_auc`
- **í•™ìŠµë¥ **: `lr`

## ğŸ”¬ ì‹¤í—˜ ê²°ê³¼

ëª¨ë¸ì€ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°€ì§‘ë‹ˆë‹¤:

1. **ì–¸ì–´ ë¬´ê´€ì„±**: ë‹¤ì–‘í•œ ì–¸ì–´ì—ì„œ ì¼ê´€ëœ ì„±ëŠ¥
2. **ë©€í‹°ëª¨ë‹¬ í•™ìŠµ**: ì˜¤ë””ì˜¤ì™€ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ë™ì‹œì— í™œìš©
3. **íš¨ìœ¨ì ì¸ ì¶”ë¡ **: ë¹ ë¥¸ ì˜ˆì¸¡ ì†ë„
4. **í™•ì¥ ê°€ëŠ¥ì„±**: ìƒˆë¡œìš´ ì–¸ì–´ ì¶”ê°€ ìš©ì´

## ğŸ¯ ì„±ëŠ¥ ìµœì í™” íŒ

1. **ë°°ì¹˜ í¬ê¸° ì¡°ì •**: GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ë°°ì¹˜ í¬ê¸° ì¡°ì •
2. **í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§**: CosineAnnealingLR ì‚¬ìš©ìœ¼ë¡œ ì•ˆì •ì ì¸ í•™ìŠµ
3. **ì¡°ê¸° ì¢…ë£Œ**: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ì¡°ê¸° ì¢…ë£Œ ì„¤ì •
4. **í˜¼í•© ì •ë°€ë„**: FP16 ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜

1. **CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±**:
   - ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
   - í˜¼í•© ì •ë°€ë„ í›ˆë ¨ í™œì„±í™”
   - ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ì‚¬ìš©

2. **ë°ì´í„° ë¡œë”© ì˜¤ë¥˜**:
   - ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ í™•ì¸
   - ë©”íƒ€ë°ì´í„° íŒŒì¼ í˜•ì‹ í™•ì¸
   - íŒŒì¼ ì¸ì½”ë”© í™•ì¸ (UTF-8)

3. **ëª¨ë¸ ë¡œë”© ì˜¤ë¥˜**:
   - ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ í™•ì¸
   - ëª¨ë¸ ë²„ì „ í˜¸í™˜ì„± í™•ì¸

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ¤ ê¸°ì—¬

ë²„ê·¸ ë¦¬í¬íŠ¸, ê¸°ëŠ¥ ìš”ì²­, í’€ ë¦¬í€˜ìŠ¤íŠ¸ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤!

## ğŸ“š ì°¸ê³  ìë£Œ

- [SigLIP2 ë…¼ë¬¸](https://arxiv.org/abs/2403.15396)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [PyTorch Lightning](https://lightning.ai/docs/pytorch/stable/)
- [Weights & Biases](https://wandb.ai/) 