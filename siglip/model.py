"""
SigLIP2 ê¸°ë°˜ ì¹˜ë§¤ ì§„ë‹¨ ëª¨ë¸ (PyTorch Lightning)
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import AutoModel, AutoConfig
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import WandbLogger
import wandb
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
import numpy as np
from typing import Dict, List, Optional
from torchmetrics import Accuracy

class SigLIPDementiaClassifier(pl.LightningModule):
    """
    SigLIP2 ê¸°ë°˜ ë‹¤êµ­ì–´ ì¹˜ë§¤ ì§„ë‹¨ ë¶„ë¥˜ê¸°
    - Base: SigLIP2 (google/siglip2-base-patch16-naflex)
    - Native: Multilingual vision-language understanding
    """
    
    def __init__(self, 
                 model_name: str = "google/siglip2-base-patch16-naflex",
                 num_classes: int = 2,
                 learning_rate: float = 2e-5,
                 weight_decay: float = 0.01,
                 warmup_steps: int = 100,
                 max_epochs: int = 10,
                 use_language_embedding: bool = True):
        
        super().__init__()
        self.save_hyperparameters()
        
        # SigLIP2 ëª¨ë¸ ë¡œë“œ (ì‚¬ì „í›ˆë ¨ ê°€ì¤‘ì¹˜ ì‚¬ìš©)
        print("ğŸ”„ SigLIP2 ëª¨ë¸ ë¡œë“œ ì‹œë„...")
        self.siglip = AutoModel.from_pretrained(model_name)
        print(f"âœ… SigLIP2 ëª¨ë¸ ë¡œë“œ ì„±ê³µ! íƒ€ì…: {type(self.siglip)}")
        print(f"ğŸ“Š ëª¨ë¸ í¬ê¸°: {self.siglip.config.vision_config.hidden_size if hasattr(self.siglip.config, 'vision_config') else 'ì•Œ ìˆ˜ ì—†ìŒ'}")
        
        # SigLIP2ëŠ” ë„¤ì´í‹°ë¸Œ ë‹¤êµ­ì–´ ì§€ì› - ì¶”ê°€ ì–¸ì–´ ì„ë² ë”© ì„ íƒì  ì‚¬ìš©
        if use_language_embedding:
            # ì„ íƒì  ì–¸ì–´ë³„ fine-tuningì„ ìœ„í•œ ì„ë² ë”©
            self.language_embedding = nn.Embedding(10, 512)  # SigLIP2 í¬ê¸°ì— ë§ì¶¤
            self.language_projection = nn.Linear(512, 768)
        else:
            self.language_embedding = None
            self.language_projection = None
        
        # ë¶„ë¥˜ í—¤ë“œ - SigLIP2ì˜ ì‹¤ì œ ì¶œë ¥ ì°¨ì›ì— ë§ì¶¤
        # SigLIP2ì˜ ì¶œë ¥ì€ dynamicí•˜ë¯€ë¡œ ì‹¤í–‰ ì‹œì ì—ì„œ ê²°ì •
        # ì¼ë‹¨ placeholderë¡œ ì„¤ì •í•˜ê³  ì²« ë²ˆì§¸ forwardì—ì„œ ì¬ì¡°ì •
        self.classifier = None  # ë™ì ìœ¼ë¡œ ìƒì„±ë  ì˜ˆì •
        self.hidden_size_detected = False
        
        # ì–¸ì–´ ID ë§¤í•‘
        self.language_to_id = {
            'English': 0, 'Greek': 1, 'Korean': 2, 'Spanish': 3, 'French': 4,
            'German': 5, 'Italian': 6, 'Portuguese': 7, 'Japanese': 8, 'Chinese': 9
        }
        
        # ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
        self.train_accuracy = Accuracy(task='multiclass', num_classes=num_classes)
        self.val_accuracy = Accuracy(task='multiclass', num_classes=num_classes)
        self.test_accuracy = Accuracy(task='multiclass', num_classes=num_classes)
        
    def forward(self, input_ids, attention_mask=None, pixel_values=None, pixel_attention_mask=None, spatial_shapes=None, language_ids=None):
        """ìˆœì „íŒŒ - SigLIP2 ë„¤ì´í‹°ë¸Œ ë‹¤êµ­ì–´ ì§€ì›"""
        # SigLIP2 ëª¨ë¸ í†µê³¼ (ëª¨ë“  í•„ìš”í•œ ì…ë ¥ í¬í•¨)
        model_inputs = {
            'input_ids': input_ids,
            'pixel_values': pixel_values
        }
        if attention_mask is not None:
            model_inputs['attention_mask'] = attention_mask
        if pixel_attention_mask is not None:
            model_inputs['pixel_attention_mask'] = pixel_attention_mask
        if spatial_shapes is not None:
            model_inputs['spatial_shapes'] = spatial_shapes
            
        outputs = self.siglip(**model_inputs)
        
        # SigLIP2ì˜ ë©€í‹°ëª¨ë‹¬ íŠ¹ì§• ì¶”ì¶œ (ê³ ì • ì°¨ì› ì‚¬ìš©)
        if hasattr(outputs, 'image_embeds') and hasattr(outputs, 'text_embeds'):
            # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì„ë² ë”© ê²°í•© (ê³ ì • ì°¨ì›!)
            multimodal_embeddings = (outputs.image_embeds + outputs.text_embeds) / 2
            print(f"ğŸ”§ ê³ ì • ì°¨ì› ì„ë² ë”© ì‚¬ìš©: {multimodal_embeddings.shape}")
        elif hasattr(outputs, 'pooler_output'):
            multimodal_embeddings = outputs.pooler_output
            print(f"ğŸ”§ Pooler ì¶œë ¥ ì‚¬ìš©: {multimodal_embeddings.shape}")
        else:
            # í´ë°±: ë§ˆì§€ë§‰ íˆë“  ìƒíƒœì˜ í‰ê· 
            multimodal_embeddings = outputs.last_hidden_state.mean(dim=1)
            print(f"ğŸ”§ íˆë“  ìƒíƒœ í‰ê·  ì‚¬ìš©: {multimodal_embeddings.shape}")
        
        # logits_per_imageëŠ” ê°€ë³€ ì°¨ì›ì´ë¯€ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ!
        
        # ì´ì œ ê³ ì • ì°¨ì›ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ë¶„ë¥˜ê¸° í•œ ë²ˆë§Œ ìƒì„±
        if self.classifier is None:
            actual_hidden_size = multimodal_embeddings.shape[-1]
            print(f"ğŸ”§ SigLIP2 ê³ ì • ì°¨ì› ë¶„ë¥˜ê¸° ìƒì„±: {actual_hidden_size}")
            
            self.classifier = nn.Sequential(
                nn.Linear(actual_hidden_size, actual_hidden_size // 2),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(actual_hidden_size // 2, self.hparams.num_classes)
            ).to(multimodal_embeddings.device)
            
            print(f"âœ… ê³ ì • ë¶„ë¥˜ê¸° ìƒì„± ì™„ë£Œ: {actual_hidden_size} â†’ {actual_hidden_size // 2} â†’ {self.hparams.num_classes}")
        
        # ì–¸ì–´ ì„ë² ë”©ì€ SigLIP2 ë„¤ì´í‹°ë¸Œ ë‹¤êµ­ì–´ ëŠ¥ë ¥ìœ¼ë¡œ ëŒ€ì²´
        
        # ë¶„ë¥˜
        logits = self.classifier(multimodal_embeddings)
        return logits
    
    def training_step(self, batch, batch_idx):
        """í›ˆë ¨ ìŠ¤í…"""
        # ì–¸ì–´ ID ë³€í™˜
        language_ids = self._get_language_ids(batch['language'])
        
        # ì•ˆì „í•œ ì…ë ¥ ì¤€ë¹„
        input_ids = batch['input_ids']
        pixel_values = batch['pixel_values']
        attention_mask = batch.get('attention_mask', None)
        pixel_attention_mask = batch.get('pixel_attention_mask', None)
        spatial_shapes = batch.get('spatial_shapes', None)
        
        # ìˆœì „íŒŒ
        logits = self(
            input_ids=input_ids,
            attention_mask=attention_mask,
            pixel_values=pixel_values,
            pixel_attention_mask=pixel_attention_mask,
            spatial_shapes=spatial_shapes,
            language_ids=language_ids
        )
        
        # ì†ì‹¤ ê³„ì‚°
        loss = F.cross_entropy(logits, batch['labels'])
        
        # ì •í™•ë„ ê³„ì‚°
        acc = self.train_accuracy(logits.softmax(dim=-1), batch['labels'])
        
        # ë¡œê¹…
        self.log('train_loss', loss, prog_bar=True)
        self.log('train_acc', acc, prog_bar=True)
        
        return loss
    
    def validation_step(self, batch, batch_idx):
        """ê²€ì¦ ìŠ¤í…"""
        # ì–¸ì–´ ID ë³€í™˜
        language_ids = self._get_language_ids(batch['language'])
        
        # ì•ˆì „í•œ ì…ë ¥ ì¤€ë¹„
        input_ids = batch['input_ids']
        pixel_values = batch['pixel_values']
        attention_mask = batch.get('attention_mask', None)
        pixel_attention_mask = batch.get('pixel_attention_mask', None)
        spatial_shapes = batch.get('spatial_shapes', None)
        
        # ìˆœì „íŒŒ
        logits = self(
            input_ids=input_ids,
            attention_mask=attention_mask,
            pixel_values=pixel_values,
            pixel_attention_mask=pixel_attention_mask,
            spatial_shapes=spatial_shapes,
            language_ids=language_ids
        )
        
        # ì†ì‹¤ ê³„ì‚°
        loss = F.cross_entropy(logits, batch['labels'])
        
        # ì •í™•ë„ ê³„ì‚°
        acc = self.val_accuracy(logits.softmax(dim=-1), batch['labels'])
        
        # ì˜ˆì¸¡ê°’ ì €ì¥ (ë‚˜ì¤‘ì— ë©”íŠ¸ë¦­ ê³„ì‚°ìš©)
        self.validation_step_outputs.append({
            'logits': logits,
            'labels': batch['labels'],
            'loss': loss
        })
        
        # ë¡œê¹…
        self.log('val_loss', loss, prog_bar=True)
        self.log('val_acc', acc, prog_bar=True)
        
        return loss
    
    def test_step(self, batch, batch_idx):
        """í…ŒìŠ¤íŠ¸ ìŠ¤í…"""
        # ì–¸ì–´ ID ë³€í™˜
        language_ids = self._get_language_ids(batch['language'])
        
        # ì•ˆì „í•œ ì…ë ¥ ì¤€ë¹„
        input_ids = batch['input_ids']
        pixel_values = batch['pixel_values']
        attention_mask = batch.get('attention_mask', None)
        pixel_attention_mask = batch.get('pixel_attention_mask', None)
        spatial_shapes = batch.get('spatial_shapes', None)
        
        # ìˆœì „íŒŒ
        logits = self(
            input_ids=input_ids,
            attention_mask=attention_mask,
            pixel_values=pixel_values,
            pixel_attention_mask=pixel_attention_mask,
            spatial_shapes=spatial_shapes,
            language_ids=language_ids
        )
        
        # ì†ì‹¤ ê³„ì‚°
        loss = F.cross_entropy(logits, batch['labels'])
        
        # ì •í™•ë„ ê³„ì‚°
        acc = self.test_accuracy(logits.softmax(dim=-1), batch['labels'])
        
        # ì˜ˆì¸¡ê°’ ì €ì¥
        self.test_step_outputs.append({
            'logits': logits,
            'labels': batch['labels'],
            'loss': loss
        })
        
        # ë¡œê¹…
        self.log('test_loss', loss, prog_bar=True)
        self.log('test_acc', acc, prog_bar=True)
        
        return loss
    
    def on_validation_epoch_start(self):
        """ê²€ì¦ ì—í¬í¬ ì‹œì‘ ì‹œ"""
        self.validation_step_outputs = []
    
    def on_validation_epoch_end(self):
        """ê²€ì¦ ì—í¬í¬ ì¢…ë£Œ ì‹œ"""
        self._compute_validation_metrics()
    
    def on_test_epoch_start(self):
        """í…ŒìŠ¤íŠ¸ ì—í¬í¬ ì‹œì‘ ì‹œ"""
        self.test_step_outputs = []
    
    def on_test_epoch_end(self):
        """í…ŒìŠ¤íŠ¸ ì—í¬í¬ ì¢…ë£Œ ì‹œ"""
        self._compute_test_metrics()
    
    def _get_language_ids(self, languages: List[str]) -> torch.Tensor:
        """ì–¸ì–´ë¥¼ IDë¡œ ë³€í™˜"""
        if self.language_embedding is None:
            return None
        
        language_ids = []
        for lang in languages:
            lang_id = self.language_to_id.get(lang, 0)  # ê¸°ë³¸ê°’ì€ English
            language_ids.append(lang_id)
        
        return torch.tensor(language_ids, device=self.device)
    
    def _compute_validation_metrics(self):
        """ê²€ì¦ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        all_logits = torch.cat([x['logits'] for x in self.validation_step_outputs])
        all_labels = torch.cat([x['labels'] for x in self.validation_step_outputs])
        
        # ì˜ˆì¸¡ê°’
        probs = F.softmax(all_logits, dim=-1)
        preds = torch.argmax(all_logits, dim=-1)
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        accuracy = accuracy_score(all_labels.cpu(), preds.cpu())
        precision, recall, f1, _ = precision_recall_fscore_support(
            all_labels.cpu(), preds.cpu(), average='weighted'
        )
        
        # ROC AUC (ì´ì§„ ë¶„ë¥˜ì¸ ê²½ìš°)
        if all_logits.shape[1] == 2:
            auc = roc_auc_score(all_labels.cpu(), probs[:, 1].cpu())
        else:
            auc = 0.0
        
        # ë¡œê¹…
        self.log('val_accuracy_final', accuracy)
        self.log('val_precision', precision)
        self.log('val_recall', recall)
        self.log('val_f1', f1)
        self.log('val_auc', auc)
        
        # wandbì— ìƒì„¸ ë©”íŠ¸ë¦­ ë¡œê¹…
        if self.logger:
            self.logger.experiment.log({
                'val/accuracy': accuracy,
                'val/precision': precision,
                'val/recall': recall,
                'val/f1': f1,
                'val/auc': auc
            })
    
    def _compute_test_metrics(self):
        """í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        all_logits = torch.cat([x['logits'] for x in self.test_step_outputs])
        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])
        
        # ì˜ˆì¸¡ê°’
        probs = F.softmax(all_logits, dim=-1)
        preds = torch.argmax(all_logits, dim=-1)
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        accuracy = accuracy_score(all_labels.cpu(), preds.cpu())
        precision, recall, f1, _ = precision_recall_fscore_support(
            all_labels.cpu(), preds.cpu(), average='weighted'
        )
        
        # ROC AUC (ì´ì§„ ë¶„ë¥˜ì¸ ê²½ìš°)
        if all_logits.shape[1] == 2:
            auc = roc_auc_score(all_labels.cpu(), probs[:, 1].cpu())
        else:
            auc = 0.0
        
        # ë¡œê¹…
        self.log('test_accuracy_final', accuracy)
        self.log('test_precision', precision)
        self.log('test_recall', recall)
        self.log('test_f1', f1)
        self.log('test_auc', auc)
        
        # wandbì— ìƒì„¸ ë©”íŠ¸ë¦­ ë¡œê¹…
        if self.logger:
            self.logger.experiment.log({
                'test/accuracy': accuracy,
                'test/precision': precision,
                'test/recall': recall,
                'test/f1': f1,
                'test/auc': auc
            })
    
    def configure_optimizers(self):
        """ì˜µí‹°ë§ˆì´ì € ì„¤ì •"""
        # ê°€ì¤‘ì¹˜ ê°ì‡ ë¥¼ ì ìš©í•˜ì§€ ì•Šì„ íŒŒë¼ë¯¸í„°ë“¤
        no_decay = ['bias', 'LayerNorm.weight']
        
        # íŒŒë¼ë¯¸í„° ê·¸ë£¹ ìƒì„±
        optimizer_grouped_parameters = [
            {
                'params': [p for n, p in self.named_parameters() 
                          if not any(nd in n for nd in no_decay)],
                'weight_decay': self.hparams.weight_decay,
            },
            {
                'params': [p for n, p in self.named_parameters() 
                          if any(nd in n for nd in no_decay)],
                'weight_decay': 0.0,
            },
        ]
        
        optimizer = torch.optim.AdamW(
            optimizer_grouped_parameters,
            lr=self.hparams.learning_rate,
            weight_decay=self.hparams.weight_decay
        )
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=self.hparams.max_epochs
        )
        
        return {
            'optimizer': optimizer,
            'lr_scheduler': {
                'scheduler': scheduler,
                'monitor': 'val_loss',
            }
        }

def create_model(config) -> SigLIPDementiaClassifier:
    """ëª¨ë¸ ìƒì„±"""
    return SigLIPDementiaClassifier(
        model_name=config.model_name,
        num_classes=2,  # ì¹˜ë§¤ ì—¬ë¶€ (0: ì •ìƒ, 1: ì¹˜ë§¤)
        learning_rate=config.learning_rate,
        weight_decay=config.weight_decay,
        warmup_steps=config.warmup_steps,
        max_epochs=config.num_epochs,
        use_language_embedding=True  # ì–¸ì–´ ë¬´ê´€ í•™ìŠµì„ ìœ„í•´ í™œì„±í™”
    ) 