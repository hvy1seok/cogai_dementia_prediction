#!/usr/bin/env python3
"""
ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

from dataset_multilingual import read_multilingual_data, prepare_multilingual_dataset
from pathlib import Path
import sys

def test_data_loading():
    """ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ§ª ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    data_dir = "../training_dset"
    
    # ê° ì–¸ì–´ë³„ë¡œ ê°œë³„ í…ŒìŠ¤íŠ¸
    languages = ['English', 'Greek', 'Spanish', 'Mandarin']
    
    for language in languages:
        print(f"\nğŸŒ {language} ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸...")
        
        try:
            # ë‹¨ì¼ ì–¸ì–´ ë¡œë“œ
            raw_data = read_multilingual_data(data_dir, [language])
            
            if len(raw_data) > 0:
                print(f"  âœ… {len(raw_data)}ê°œ ìƒ˜í”Œ ë¡œë“œë¨")
                
                # ì²« ë²ˆì§¸ ìƒ˜í”Œ í™•ì¸
                sample = raw_data[0]
                print(f"  ğŸ“„ ìƒ˜í”Œ ì˜ˆì‹œ:")
                print(f"    í…ìŠ¤íŠ¸: {sample['text'][:100]}...")
                print(f"    ì˜¤ë””ì˜¤ ê²½ë¡œ: {sample['audio_path']}")
                print(f"    ë¼ë²¨: {sample['label']}")
                print(f"    í™˜ì ID: {sample['patient_id']}")
                
                # ë¼ë²¨ ë¶„í¬ í™•ì¸
                labels = [item['label'] for item in raw_data]
                normal_count = labels.count(0)
                dementia_count = labels.count(1)
                print(f"  ğŸ“Š ë¼ë²¨ ë¶„í¬: ì •ìƒ {normal_count}ê°œ, ì¹˜ë§¤ {dementia_count}ê°œ")
                
                # ì˜¤ë””ì˜¤ íŒŒì¼ ì¡´ì¬ í™•ì¸
                audio_exists = 0
                for item in raw_data[:10]:  # ì²˜ìŒ 10ê°œë§Œ í™•ì¸
                    if Path(item['audio_path']).exists():
                        audio_exists += 1
                
                print(f"  ğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ì¡´ì¬ìœ¨: {audio_exists}/10")
                
            else:
                print(f"  âŒ ë°ì´í„° ì—†ìŒ")
                
        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    print(f"\nğŸŒ ì „ì²´ ì–¸ì–´ í†µí•© í…ŒìŠ¤íŠ¸...")
    
    try:
        # ì „ì²´ ì–¸ì–´ ë¡œë“œ
        all_data = read_multilingual_data(data_dir, languages)
        
        if len(all_data) > 0:
            print(f"  âœ… ì´ {len(all_data)}ê°œ ìƒ˜í”Œ ë¡œë“œë¨")
            
            # ì–¸ì–´ë³„ ë¶„í¬
            from collections import Counter
            lang_dist = Counter([item['language'] for item in all_data])
            print(f"  ğŸ“Š ì–¸ì–´ë³„ ë¶„í¬:")
            for lang, count in lang_dist.items():
                print(f"    {lang}: {count}ê°œ")
            
            # ë¼ë²¨ ë¶„í¬
            label_dist = Counter([item['label'] for item in all_data])
            print(f"  ğŸ“Š ì „ì²´ ë¼ë²¨ ë¶„í¬:")
            print(f"    ì •ìƒ: {label_dist[0]}ê°œ")
            print(f"    ì¹˜ë§¤: {label_dist[1]}ê°œ")
            
            print(f"\nâœ… ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            return True
            
        else:
            print(f"  âŒ ì „ì²´ ë°ì´í„° ì—†ìŒ")
            return False
            
    except Exception as e:
        print(f"  âŒ ì „ì²´ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        return False

def test_tokenization():
    """í† í°í™” í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ”¤ í† í°í™” í…ŒìŠ¤íŠ¸...")
    
    try:
        # ì‘ì€ ìƒ˜í”Œë¡œ í† í°í™” í…ŒìŠ¤íŠ¸
        dataset = prepare_multilingual_dataset(
            data_dir="../training_dset",
            max_seq_len=128,
            languages=['English'],  # ì˜ì–´ë§Œìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        )
        
        if len(dataset) > 0:
            print(f"  âœ… {len(dataset)}ê°œ ìƒ˜í”Œ í† í°í™” ì™„ë£Œ")
            
            # ì²« ë²ˆì§¸ ìƒ˜í”Œ í™•ì¸
            sample = dataset[0]
            print(f"  ğŸ“„ í† í°í™”ëœ ìƒ˜í”Œ:")
            print(f"    input_ids shape: {sample['input_ids'].shape}")
            print(f"    attention_mask shape: {sample['attention_mask'].shape}")
            print(f"    audio shape: {sample['audio'].shape}")
            print(f"    label: {sample['label']}")
            print(f"    language: {sample['language']}")
            
            return True
        else:
            print(f"  âŒ í† í°í™”ëœ ë°ì´í„° ì—†ìŒ")
            return False
            
    except Exception as e:
        print(f"  âŒ í† í°í™” ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("="*60)
    print("ğŸ§ª ë‹¤êµ­ì–´ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
    loading_success = test_data_loading()
    
    if loading_success:
        # í† í°í™” í…ŒìŠ¤íŠ¸
        tokenization_success = test_tokenization()
        
        if tokenization_success:
            print(f"\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
            print(f"ì´ì œ main_multilingual.pyë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            sys.exit(0)
        else:
            print(f"\nâŒ í† í°í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            sys.exit(1)
    else:
        print(f"\nâŒ ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        sys.exit(1)
